大家好 这里是最佳拍档 我是大飞
其实一直有很多人问我
Prom要怎么写效果才好 有没有什么模板
虽然每次我都会说
能够清晰的表达你的想法才是最重要的
各种技巧都是其次
但是我还是希望能有一些靠谱的文档
给他们做参考
可惜的是网上的各种所谓的Prom框架
教程真的是乱七八糟 让人头大
直到上个月15号
OpenEye在他们的文档里上线了官方的提示词工程指南
到此总算是有了一个权威
而且有效的提示工程的标准文档了
我看完之后觉得整篇指南简洁明确高效
写得非常好
可以秒杀市面上99%的提示工程框架和技巧
今天就来跟大家分享一下
OpenEye提到了6条大的原则
分别是 1 写出清晰的指令
2 提供参考文本
3 将复杂的任务拆分为更简单的子任务
4 给模型时间去思考
5 使用外部工具
6 系统的测试变更
其中第6条可以不看
对普通的用户没什么用处
首先第一条原则 写出清晰的指令
其实就是我们天天说的
要把你需要解决的问题说清楚 讲明白
这就像是人与人沟通一样
话都说不明白 怎么能让别人理解你呢
一味的靠抄提示模板 显然也不是长久之计
写出清晰的指令才是核心中的核心
举个例子 假设我们想了解
2021年的时候谁是美国总统
甚至更进一步还想知道
他是否目前仍然是总统
如果我们扔给ChadGBT一句 谁是总统
别说是ChadGBT了
就算是政治老师也会是一脸的懵逼
更好的提示应该是这样
2021年谁是美国的总统
美国几年举行一次选举呢
OpenEye在指南中还列出了一个
Worst or Better的事例供大家参考
此外 OpenEye对于如何写出清晰的指令
还给出了六条小技巧
第一条 把话说详细
尽量多的去提供
任何重要的详细信息和上下文
说白了 就是要把话说得明白一点
不要太笼统
假设我们要去进行一个会议的总结
如果我们期望ChadGBT
可以给我们良好的一个回复
那么我们就不应该直接扔进去一句话
比如说帮我总结这份会议笔记
而是要将我们的需求讲明白
比如 首先使用简单的一段总结
来概括这份会议笔记的主要内容
其次将会议中的各个发言者的核心观点
以Markdown的格式分条的列出
最后 如果有的话
列出每个发言者提出的
下一步行动计划和方案
显然后者的描述是更为清晰的
更有可能得到我们想要的答案
第二条 让模型充当某个角色
你可以把大模型想象成一个演员
你要告诉他让他来演什么角色
他就会更加的专业 更加的明确
跟这个是一个道理
比如说你可以这么去写提示
请你充当一个喜欢讲笑话的喜剧演员
每当我请求帮助写一些东西的时候
你会回复一份文档
其中每个段落至少包含一个笑话
或者有趣的评论
第三条 使用分格符
清晰的指示书的不同部分
像3引号、XM标签、节标题这些分格符
都可以用来帮助划分要区别对待的文本节
这样可以帮助大模型更好的理解文本的内容
第四 指定完成任务所需要的步骤
有些任务能拆就拆
最好指定为一系列的步骤
然后明确的写出这些步骤
这样可以是让模型更加的容易去实现它们
比如说你可以编写这样一个提示
使用以下分布说明来响应用户的输入
步骤一 用一个句子总结这段文字
并加上前缀 summary
步骤二 将步骤一中的摘要翻译成西班牙语
并添加前缀翻译
第五 提供例子
也就是经典的少样本提示
FillshotPrime
先扔给大模型一个例子
让大模型按照你的例子来输出
比如说按照某句话的特定风格来写
第六 指定所输出的长度
你可以要求模型生成给定目标长度的输出
目标输出长度可以根据单词 句子 段落 要点等等这些技术来指定
不过对于ChatGVT来说 中文的效果不是很明显
同时你给定的长度只是一个大概
多少个字这种肯定不会非常的精准
但是像多少段这种效果就会比较好
比如说用两个段落一百个字符
来概括一段由三引号分隔的文本
那说完第一条原则
我们再来说第二条 提供参考文本
也就是通过给大模型文本或者是文档
能够大幅度的降低大模型胡说八道的概率
其实就是把大模型当做知识库来用
这里边又分成两类
第一类是让模型使用参考文本做答案
这也是知识库的经典用法
比如说使用提供的三引号内的文章来回答问题
如果在文章中找不到答案 请写我找不到答案
然后跟上问题是什么
第二类是让模型通过引用参考文本来回答
或者为答案去添加一些引用
从而提高正确性 增加可验证性
第三个原则是将复杂的任务
拆分为更简单的子任务
其实这个跟我们人类也是一样的
如果你是一个老板
让下属一次性去做一个非常大的事情
那么出错的概率是很大的
很多的大项目也是这样
你甚至无从下手
所以我们经常要在工作中
都要去拆分任务
拆各种细节 子任务 子目标等等
大模型也是同样的道理
把复杂的任务给拆成更简单的子任务
大模型就会有更好的表现
这里面又有几种的方式
首先第一种是使用意图分类
来识别与用户查询最相关的指令
意图识别是一个很经典的例子
比如说在客服的场景中
用户问了一个问题
我家断网了 该怎么办
你让大模型直接回复这个问题
其实是很蛋疼的
但是这时候你就可以拆
先拆大分类下的意图识别
再回答具体的问题
比如还是我家断网了
该怎么办这个问题
我们开始先对问题进行分类
然后根据输入来判断问题的类别
现在大模型根据提示至少知道
我家断网了该怎么办
这个问题是属于技术支持中的
故障排除了
然后我们就可以再继续的进行
这时候用户的问题
就能得到非常有效的回答了
第二种是对于需要很长对话的
对话型应用
总结或者是过滤之前的对话
这个技巧偏向于开发者
普通用户也可以跳过
因为模型具有固定的上下温长度
所以用户和模型之间的对话
无法无限期的去继续
解决这个问题有很多种的方法
第一个是总结对话中的历史记录
一旦输入的大小
达到了预定的预值长度
这可能就会触发
总结部分对话的查询
并且先前对话的摘要
可以作为系统消息的一部分
包括在内
或者可以在整个对话过程中
在后台一步的总结之前的对话
这两种方法都可以
或者还可以把过去的所有聊天记录
存到相量数据库
后续跟用户对话的时候
动态的查询嵌入
这也是可以的
第三种是分段总结常问档
并且递归的构建完整的总结
这种方式同样会偏向于开发者
其实就是总结几百页PDF文档的原理
比如说让大模型去总结一本书
肯定会超过Token的上限
所以可以使用一系列的查询
来总结文档的每个部分
章节的摘要可以不断的连接和总结
比如生成摘要的摘要
这个过程可以递归的进行下去
直到总结出整个文档
OpenAI在之前的研究中
已经使用GPT-3的变体
研究了这种总结书籍的过程的有效性
第四条原则
给模型时间思考
这也就是Think step by step
一步一步思考这个神级提示词的源头
其实也就是链式思考COT
Chain of thought
这对于提示来说
是非常非常有用的一个策略
还是跟人一样
如果我直接问你两个大数的相乘
你肯定一下子也懵逼
但是我要给你时间
让你一步一步的去计算
只要你学过小学数学
都能够算得出来
OpenAI在COT的基础上
又详细给出了三个技巧
第一个
让模型在急于得出结论之前
先找出自己的解决方案
比如说你扔个数学题给大模型
你让它判断对或者不对
你会发现结果会很随机
一会儿对一会儿不对
但是如果你先让它自己做一遍
再去判断对与不对
结果就会准确非常多了
比如说你可以这样去写提示
首先制定自己的问题解决方案
然后将你的解决方案
与学生的解决方案进行比较
并评估学生的解决方案是否正确
在你自己完成问题之前
不要去决定学生的解决方案是否正确
第二点
使用内心读白来隐藏模型的推理过程
这是一个非常有意思的技巧
你可能会问
不是说一步一步思考
把推理过程放出来效果会更好吗
没错
不过我们现在说的这条技巧
是也是面对开发者的
对于某些应用程序来说
大模型用来得到最终答案的推理过程
并不适合与用户分享
比如说在辅导作业的应用程序中
我们可能希望鼓励学生得到自己的答案
但是模型关于学生解决方案的推理过程
可能会向学生去揭示这个答案
所以就有了这么一个内心读白的技巧
内心读白的想法
是让模型将原本对用户隐藏的部分输出
放入到结构化格式中
以便于解析它们
然后在向用户呈现输出之前
将解析输出
并且仅使部分的输出可见
接下来我们可以让模型使用所有可用的信息
来评估学生解决方案的正确性
最后我们可以让大模型使用自己的分析
以乐于助人的导师的角色来构建回复
这样我们就通过多次跟API通讯的方式
同时隐藏了模型的推理过程
来完成了一次对学生的辅导方案的对话
第三点
询问模型在之前的过程中
是否遗漏了什么内容
这个技巧在长文本问答中很常用
比如说我们给了一个文档
要让大模型列出与某个特定问题相关的信息
如果原文档很大
模型通常会过早的停止
并且无法列出所有相关的信息
在这种情况下
通过使用后续的提示
让模型查找之前传递中错过的任何相关信息
通常可以获得更好的性能
比如说
我让它根据我的文档列出北京烤鸭为什么好吃
这个问题在文档中的相关片段
那么在输出停止以后
我们可以再问一句
还有更多相关片段吗
注意不要重复摘录
并且确保包含解释他们所需要的
所有的相关的上下文
第五条原则
使用外部工具
大模型并不是万能的
很多时候大模型的效果并没有那么好
比如说回答数学问题
或者一些实时的问题的时候
所以需要一些外部的工具来帮助处理
换句话说
如果第三方工具能够稳定的获取结果
那其实并不需要大模型去做什么
或者只是让大模型去做一个
答案组装的工作就可以了
第三方工具大致可以分为三类
第一类是使用基于嵌入的搜索
来实现高效的知识检索
绝大部分知识库的原理
都是检索增强生成
也就是我们常说的RAD
但是如果我们要问他
如何评价一部即将上映的电影
那大模型自己去答肯定就废了
因为他是静态的
根本不知道这部电影的信息
所以需要先去互联网进行查询
查完以后把一堆的资料灌回来
让大模型自己根据自己查到这些资料
再进行回答
这就是所谓的动态信息
当然也有一些静态的知识库
会采用向量检索和向量匹配的方式
来实现知识检索的功能
这里我们就不多赘述了
第二类是执行代码
来进行更准确的计算
或者是调用外部的API
OpenAI也知道
大模型的计算能力是很垃圾的
所以他自己也建议
如果遇到需要计算的东西
最好让大模型去写一段计算的
Python代码
毕竟用Python做计算题
已经是很成熟了
当然了
你也可以把自己的API文档
复制给大模型
让他知道该如何去写代码
调用你的API
第三类给模型提供特定的功能
这也是一个很偏开发者的一个技巧
普通用户可以直接跳过
简而言之
就是你可以通过API的请求
传递一系列特定的函数描述
告诉模型哪些函数是可以用的
以及这些函数的参数
应该是什么样
然后模型就可以生成相应的函数参数
随后这些参数
会以Jason的格式通过API返回
在拿到Jason数据之后
你就可以做很多数据查询
数据处理的工作
处理完以后
再返回一个Jason的数组给大模型
让大模型把它变成人类的语言
输出给用户
第六条原则
系统的测试变更
这部分主要是帮助开发者来判断
更改提示语
是否能让系统变得更好
或者是更差
毕竟大部分时间的样本量
都是比较小的
很难区分真正有改进
还是纯粹的靠运气
所以OpenAI建议搞一个评估程序
用来判断优化系统的设计是否有效
这块我就不细说了
有兴趣的
或者是正在开发自己AI应用的
可以自己去看一下
以上就是OpenAI官方提示工程指南的
核心内容
我个人觉得比市面上大多数的
框架和课程都要好
其实关于如何编写提示的指南
像谷歌微软Notion
很多公司也都做过专门的文章讨论
核心观点其实与OpenAI的都略有类似
比如谷歌的教程就提到
清晰的传达最重要的内容或者信息
也就是说清楚你的目的
在构造提示词的时候
首先可以定义其他的角色
提供上下文或者是输入数据
然后给出指令
可以提供具体的多样化的例子
能够让模型参照例子
来生成更准确的结果
同时使用限制条件
来限制模型的输出的范围
避免它产生与指令无关
或者是不准确的信息
那对于复杂的任务
可以分解成一系列更简单的提示词
并且在最后加一句
让我们一步一步思考
这样就可以让模型
按照严谨的逻辑推理过程输出结果
而在Notion的教程中还提到
在提示词里描述任务要求的时候
不要使用负面的描述
其次就是AI并不擅长区分好坏
但是很擅长模仿
所以如果要让AI做某件事情
是某个人设所擅长的
那么尽量让AI来代入到
那个人设就好了
好了 本期视频内容就到这里
希望对大家编写提示有所帮助
详细内容也可以去仔细的看一下
OpenEye的官方文档
感谢大家的观看
我们下期再见
