2020年的时候
有一篇博客冲到了Hacker News的第一名
Hacker News是在技术圈里面
应该是影响力最大的一个新闻汇聚网站
所有人都可以分享自己喜欢的文章
然后观众对这些文章进行点赞或者是评论
Hacker News根据你点赞的个数和评论来进行排名
这篇文章能排到第一位
意味着大家还是挺喜欢的
然后来看一下标题
标题是说
你是不是感觉工作没有状态
也许你就是应该停止想太多
这是一个非常激烫的标题
在微信公众号上
你可能会看到许多类似的文章
然后我们点进去这篇文章看一下
它写的还是挺正常的 对吧
有一个图 这个配图也是正确的
然后里面有些文字
我就给大家一一讲了
段落有长有短
看上去是怎么回事
然后文章也挺长的
然后这件事情又上了另外一个头条
这一次上的头条是在MIT的技术评论里面
这是一个老牌的技术评论杂志
它的标题叫做说
一个大学生做了一个假的
然后由AI生成的博客
然后呢 糊弄了上外人
事实上我们刚刚看到那篇文章
是一个叫做
Nothing but the words的博客里面的一篇文章
这个博客里面其实还有听多别的文章
看上去都是模式样
但是整个博客是由模型生成的
这个模型叫做GPT-3
它文章的第一段话是想说
在某个星期的早一点时刻
有一个小哥听到了这个模型
然后他就在这个信息里面
用这个模型生成了这一个博客
非常的简单
在过去几年里面
整个自然语言处理界
可能最出圈的模型
应该就是GPT-3了
这个模型来自于OpenAI的团队
在这个模型放出来之后
整个网络上就把这个模型玩出了花了
如果你去搜一下GPT-3的应用的话
你可以搜出上百个
比如说我们随便找一篇文章
给大家看一下里面到底有什么东西
这篇博客是写于2020年的7月22号
你现在已经很久了
当然现在有更多的应用出来
我们先看一下当时候
大家已经有些什么很奇怪的玩法
它里面就转载了当时候大家用GPT-3
来玩各种应用的一些例子
比如说这里有个小哥
用GPT-3来写一个
基于React的一个duce size的一个模块
然后他在方框里面填好说
我需要一个按钮
他能够给我来duce size
然后把我的值写信出来
也把它放进去之后
然后GPT-3来给你生成你的HTML代码
然后你的结果就显示在这个地方
你看按一下这个地方之后
他告诉你说现在的值是3
他又把他的要求改了改
他说我需要一个button
跟之前一样
然后需要在你输出的时候
把你的值是3改成你现在
丢了一个什么东西的值出来
然后用GPT-3来生成之后
他又给你生成相应的代码
然后来看一下效果
你看这个是HTML代码在这个地方
然后他的结果在这里
他真的把你的结果改成了你要的形式
你多按几次
每一次他就随机生成一个数值
往下翻就是另外一些应用了
图灵测试是说我在墙的后面
放一个电脑或放一个人
你跟他对话
但是你完全分不出来
到底他是人还是电脑
比如说他用来生成了一些回答的一些例子
比如说这个问题是说
你最喜欢的动物是什么
说我最喜欢狗
然后你问说你为什么
他说狗比较忠诚而且比较友好
下面一个是一个稍微不一样的问题
当然是这个是相对来说比较简单的
因为它不是很长的对话
长对话更加难
因为你得把前面那些上下文信息
都给你记住
然后下面有一个难一点的
我填一个人名
让他来模仿这个人说话
来回答你的问题
比如说他填的是Ether Mask
让你来回答什么是火箭
然后他就模仿Ether Mask
给你回答说火箭是长什么样子的
但这个东西就不好评判
因为我也不知道Ether Mask
真的来讲会怎么样子
下面还给英勇士说
我在一个方框里面讲说
我要设计一个什么样的东西出来
他打了一段非常长的话在里面
然后再点生成
可以看到是说
他可以真的把你这一个东西生成
纯以差不多想要的形式在这个地方
最后一个例子是说
我给你一段技术性比较强大化
然后你把它改写一下
使得不那么技术的人也能够听懂
这个地方他是从GBT-3的论文里面
直接copy的一段话进去
然后在这个地方上面把它改写成
相对来说用比较简单的句式
每一句都比较短
然后是因为所以
因为所以这样子的句式
大家可以去看一下
当然这个地方只是列了一些应用
OpenAI它推出了一个
基于GBT-3的一个API
使得你能调用这个模型
开发你任何想用的应用
这里有一个网站叫做GPT-3 Demos
它这个地方列举了
目前来说
我们知道所有基于GPT-3的做的一些应用
可以看到这里面大概有几百个的样子
各个地方都有
我们来看一下都有哪一些比较流行的类别
比如说这个地方用AI来辅助你的写作
然后这个是一个聊天机器人
然后下面还有一些开发工具
然后所有东西加起来
大概有好几百的样子
最近的一个基于GPT-3的应用
大家可能也听说过
这就是GitHub Copilot
它的意思是说
你可以通过注释来说
我要写一个函数干什么事情
然后把函数签名给定之后
剩下的函数的主体
就怎么实现它可以用代码来自动生产
这个工作引起了巨大的反响
在之后有数个工作对它进行了研究
好
这就是对GPT-3的目前的一些应用的
一个非常快速的一个预览
我们今天的任务
就是来讲GPT-3这篇诺文
如果我们要讲GPT-3这篇文章
我们就不得不提到它前面的两个工作
GPT-2和GPT
在这个地方
我们把这三篇文章
和我们之前讲过的Transformer和Bird
这两篇文章分别列在这个地方
横着这条线表示的是时间轴
我们可以看到Transformer
我们首先发表在2017年的6月
在一年之后GPT出来了
我们之前也有讲过
GPT它的核心技术是
把Transformer的解码器给你拿出来
然后在没有标号的大量的文本数据上
训练一个语言模型
来获得一个预训练模型
然后再用它在子任务上做微调
得到每一个任务所要的分辨器
这个跟我们之前的
计算机视觉用的技术很一样了
然后在四个月之后
Bird出来了
我们之前有提过
据小道消息是Bird的一作
是在一两个月之内
把这篇文章做出来的
很有可能是它在看到了
GPT这篇文章之后
才有的idea
Bird的思想是说
我跟GPT不一样
我是把Transformer的编码器拿过来
然后我收集了一个更大的数据集
用来做预训练
结果效果比GPT好很多
我们回忆一下Bird
里面一共有两个模型
一个叫BirdBase
一个叫BirdLarge
BirdBase的选择
就是跟GPT的模型大小是一样的
BirdLarge当然是比BirdBase要大一些
结果上来说
BirdBase应该是要比GPT要好
而BirdLarge又甩出了BirdBase一条件
然后在另外四个月之后
GPT2出现了
GPT2又是原作者这帮人
吸取了前面的教训
哪里跌倒就在哪里爬起来
他们收集了一个更大的数据集
训练了一个更大的模型
GPT2的模型比BirdLarge是要大的
如果你就简简单单的
训练了一个大的模型
那你在信义度上肯定是有问题的
所以他就沿着了自己的技术路线
继续使用Transformer的解码器
来深入挖掘语言模型的潜力
然后他发现这个非常适合做Zero Shot
但是因为你走得比较远
所以导致效果上没有那么的惊艳
于是在一年又三个月之后
也就是2020年的5月份
他们推出了GPT3
GPT3对GPT2的改进就是
数据和模型都大了100倍
暴力出了奇迹
然后终于把效果做到非常惊艳
也就是我们之前看的这些应用的效果
非常的炸裂
也就是GPT3的效果
所以这一期视频的封面就是暴力出奇迹
然后我们这里画了两个logo
一个是OpenAI
一个是Google
因为Transformer和Bert都来自于Google的团队
然后GPT系列三篇文章都来自于OpenAI这个团队
有意思的是OpenAI团队虽然投入了很多做了GPT系列
但是它在学术界的影响力似乎是不如Bert的
这里我们列举了到目前为止他们的应用
Bert这篇文章的应用是27000次
如果你把GPT、GPT2、GPT3三篇文章的应用
加起来大概是11000次的样子
还不到Bert的1/2
GPT系列它的应用率稍低塌倒
不是因为它的创新度或者是它的效果不如Bert系列
恰恰相反
我觉得是因为OpenAI选择去解决一个更大的问题
所以它的技术上实现更难一些
它要出效果更难一些
比如说你要出到很炸裂的效果
你得做到GPT3
它这个规模几乎是没有别的团队
能够复显他们结果的
OpenAI选择这样子的技术问题去解决
是因为它整个公司它还是想做强人工智能
它想去解决一个更大的问题
所以他们必须在选择问题上选择大一点
反过来讲就是Former和Bert系列
都是来自于Google独立的一些研究组
他们一开始想解决的问题其实都比较小
趁Former我们之前也提过
它其实就想解决机器翻译这样子的例子
从一个序列翻译到另外一个序列它上面的效果
Bert其实也是挺实在的
它就是想把计算机视觉成熟的
先训练一个预训的模型
然后再做微调出指任务的结果
这一套搬过来在NOP上做好
因为他们就是想实时再提升技术的效果
所以在同样模型大小
比如说是一个亿级别模型大小
时候Bert的性能是要好于GPT的
也就是未来的工作
更多愿意用Bert这些的文章
因为我咬一咬牙还是能找到足够的机器
能把我的模型刨起来
而且效果不错
不然你如果要跟GPT系列的文章的话
可能帮你卖了你还是跑不起那个实验
好 接下来我们就按顺序
从GPT、GPT2、GPT3组一读一下每一篇文章
先看GPT
GPT文章的标题叫做
使用通用的预训链来提升语言的理解能力
GPT跟我们之前说的很多文章一样
它并没有给自己的方法起标题
所以GPT的名字来自于后面人给它的
G P T这三个字母组合在一起
如果大家对自己的硬盘做过格式化分区的话
你可能也听说过GPT
所以幸好这个工作有一定的知名度
而且OpenAI的作者在之后持续对它改进有GPT2、GPT3
不然的话你现在去搜GPT的话
可能就搜不到这篇文章
而是搜到的是硬盘如何分区了
它的作者这里有四个人
一座是Alec Redford
这个人在GPT工作之前
还有挺多有名的工作
比如说这是他Google Scholar的界面
可以看到他其实引用最高的文章是DCGAN这篇文章
就是用绝境神君网络来替换掉GAN里面的MLP
另外一个是PPO
这也是强化学习里面一个很常见的优化算法
还有是他又做了一个GAN的工作
然后后面的三个工作就是GPT这三部曲了
最后一名作者Eliya
相信大家还是记得吧
Alex Net作者的二座
然后他去了OpenAI当任了CTO
所以OpenAI很多工作
应该是挂了他的名字作为最后一个作者了
接下来我们来看一下摘要
摘要写得比较简单
我们先来看一下前面两句话
讲的是我要解决什么问题
他说在自然语言理解里面有很多不一样的任务
然后说虽然我们有很多大量的没有标号的文本文件
但是标好的数据是相对来说比较少的
这使得我们要去在这些标好的数据上
训练出分辨模型的话会比较的难
因为我们的数据相对来说还是太小了
接下来就讲作者怎么解决这个问题
他的解决方法是说
我们先在没有标号的数据上面训练一个预训练模型
这个预训模型是一个语言模型
接下来在有标号的这些子任务上面
训练一个分辨的微调模型
这个在计算机视觉里面早在89年前
已经是成为主要的算法
但是在NLP领域一直没有流行起来
是因为在NLP里面没有像Image那样
大规模标好的那种数据
在计算机视觉里面
我们有标好的100万张图片的ImageNet
在NLP的话并没有那么大数据集
虽然说机器翻译那一块
我们也许能做到100万的量级
但是你一个句子和一个图片不在一个尺度上面
一张图片里面含有的信息
像素的信息比一个句子里面能去抽取的信息来得多很多
所以一张图片可能能换十个句子的样子
意味着是说你至少有一千万级别的
句子级别的标好的数据集
才能够训练比较大的模型
这导致在相当一段时间里面
深度学习在NLP的进展没有那么的顺利
直到GPT和后面的Bert的出现才打开了局面
注意这里我们还是像计算机视觉那样
先训练好预训练模型再来做微调
但是这个不一样的是说
我们使用的是没有标号的文本
这个就往前走了一大步
然后在GPT系列后面的文章
再做ZearShot那样走了另外一大步
如果说深度学习前面五年
主要是计算机视觉在引领整个潮流的话
那么最近几年可以看到
这些创新很多来自于自然语言处理界
而且这些创新也在返回回计算机视觉里面
比如说之前我们读过的MA1这篇文章
就是把Bert用回到计算机视觉上面
我们在上期介绍的Clip
也是打通了文本和图像
当然在在原处理界
用没有标号的文本也不是第一次了
比如说十几年前就很火的
Word2vec这个词嵌入模型
就是用的大量的没有标号的文本
但是它在这里说
我们跟之前工作了一个区别是说
他们是在微调的时候
构造跟你任务相关的输入
从而使得我们只要很少的
改变我们模型的架构就行了
这是因为文本跟图片不一样
它的任务更加多样性一些
有些人说我要对词进行判断
有些人需要对句子进行判断
有些人说我需要一对句子或者三个句子
还有一些应用是说
我要生成一个句子
所以导致每个任务都需要有自己的模型
我们最早的词嵌入只是做一个词上面的学习
然后你的后面的模型还得去构造
之前的一些工作需要把你的模型
进行一些改变来适应各个任务
但是这个地方
我们只要改变输入的形式就行了
而不需要改变用的模型
当然我们读过Bird的话
我们知道这个是怎么做的
但是GPD是在Bird之前
所以它提出来的时候
在当时来说
当然是有新意的
最后实验结果可以看到是说
它在12个任务里面有9个任务
能够超过当前最好的成绩
所以看上去是稍微弱于Bird之后的结果
它在十几个任务上都超越了前面
所以导致是说Bird为什么出来之后
比GPD更加有影响力
因为它效果更加好一点
但是从创新度来讲
我觉得GPD应该在Bird之上
因为它毕竟是前面的工作
Bird在很多时候跟它的思路是一样的
接下来我们来看一下导演
导演的第一句话
讲的是我们之前提到的那个问题
就是怎么样更好地利用无监督的文本
作者提到在当时候
最成功的模型还是磁嵌入模型
然后接下来第二段话是讲
用没有标号文本的时候
使用它遇到的一些困难
它主要讲了两个困难
第一个困难是说
你不知道用什么样的优化目标函数
就是我给你一堆文本
你到底你的损失函数长什么样子呢
当时候有很多选择
比如说你有语言模型
你有机器翻译
或者是文本的一致性
但是问题是说
没有发现某一个特别的好
就一个目标函数在一些任务上比较好
另外一个目标函数在另外一些问题上又比较好
就是说看你的目标函数
跟你持之要做的子任务
它的相关度有多高了
第二个难点是说
怎么样有效的把你学到的这些文本的表示
传递到你下游的子任务上面
这也是因为NLP里面的子人物
差别还比较大的
没有一个简单的统一的有效的方式
使得一种表示能够一致的迁移到所谓的子任务上面
好 接下来第三个就是说
GPT这本文章它提出了一个半监督的方法
然后在没有编号的文本上面
训练一个比较大的语言模型
然后再在子任务上进行微调
当然我们现在对这一套比较熟悉
但是有意思的说
你回到当年作者用的是半监督学习这个词
就Semi-supervised
半监督学习在记忆学习期间
可能在十年前是非常的火的
它的核心思想是说
我有一些编号的数据
但我还有大量的相似的但没有编号的数据
我怎么样把这些没有编号的数据用过来
那就是半监督学习想学的东西
这个地方呢
当然是可以放到半监督学习里面
就是说你在没有编号的模型上面
训练好一个模型之后
然后再在有监督的上面做微调
但是呢半监督学习里面还有很多别的算法
但现在我们把GPT这一套方法和Bert之后
所谓的工作也用到了类似的方法
不叫做半监督学习
而叫自监督学习
叫做Self supervised learning
这也是上一期的Clip那篇文章
作者有说到同一个方法
但是在不同的论文的作者把它归类成不一样的算法
下一段讲的是他用到的模型
可以看到它主要是有两点
第一点是说它的模型是基于Transformer这个架构的
因为这篇文章发表在Transformer这篇文章出来一年之后
当然作者在做这个工作的时候
应该可能更早
可能是Transformer出来就几个月
所以在试用Transformer还是用RN这种模型的时候
在当时候不是那么显而易见的
所以作者解释了一下大概的原因
他说跟RN这种模型相比
他发现Transformer他在芊怡学习的时候
他学到的那些feature更加的稳健一些
作者觉得原因可能是因为Transformer里面有更结构化的记忆
使得能够处理更长的这些文本信息
从而能够抽取出更好的巨子层面和段落层面的这些余意信息了
第二个技术要点是说他在做芊怡的时候
用的是一个任务相关的书的一个表示
我们在之后会看到它到底长什么样子
最后一段只讲我的实验结果了
我们就不在这里给大家看了
下面是相关工作
相关工作我们就不给大家仔细讲了
他就讲了一下在NLP里面半监督是怎么回事
然后讲的是无监督的运行链模型
还有是说我在训练的时候需要使用多个目标函数的时候会怎么样
这分别对应的是你的大的GPD模型怎么样在没有标号的数据上训练出来
以及说你怎么样在子任务上用有标号的数据进行微调
最后的时候你在做微调的时候
他使用了两个训练的目标函数
第三章就是讲这个模型的本身
我们来看一下
这一节里面有三个小节分别对应的是我怎么在没有标号的数据上训练模型
怎么样做微调
以及说我怎么样对每个子任务表示我的输入
我们先来看3.1
就是在没有标号的数据上面做预训练
假设我们有一个文本没有标号的文本
里面每个词呢表示成一个UI
那么它整个文本就表示成ue知道un
它是有个序列信息的
就词我们不会交换你的顺序
GPD使用一个标准的语言模型的目标函数
来最大化下面这一个自然函数
我们来看一下是怎么回事
具体来说语言模型就是要预测第二个词出现的概率
那么第二个词即为UI
它怎么预测呢
它是把UI的前面的k个词
就是UI-1一直到UI-k
k这个地方是你的窗口大小或者要说上下文窗口
也就是说每一次我们拿k个连续的词
然后再预测这k个词后面哪一个词是谁
具体来说它的预测是用一个模型
这个模型继承file的这个地方
给定你k个词给定模型
那么预测这k个词下一个词它的概率
把每一个这样子的词就是I
它的位置从01直到最后
把全部加起来就得到我们的目标函数
这个地方即为L1
它不是你的那个范式里面的L1
它就是第一个目标函数
因为它后面还有一个别的目标函数
它为什么是加是因为去log的缘故
如果你做指数放回去的话
那就是所有这些词出现的概率相乘
也就是这个文本出现的联合概率
就是说我要训练一个模型
使得它能够最大概率的输出
跟我的文本长得一样的一些文章
所以这个地方file模型是你的参数
k是你的超参数
就是你的窗口的大小
从神经网络角度来言
那你k就是你输入序列的长度
你的序列越长的话
你的网络看到东西就越多
就是它越会倾向于在一个比较长的文本里面
去找里面的关系
你k越短的话
当然你的模型相对说比较简单
只要看比较短的就行了
所以这个地方
如果你想让你的模型很强的话
那么k可能要去到几十几百
或者甚至上千
它在下面又解释了一下具体这个模型是谁
它用到的模型是Transformer的解码器
我们回忆一下Transformer有两个东西
一个是编码器
一个是解码器
它们最大的不一样在于是说
编码器来一个序列进来
它对第二个元素抽特征的时候
它能够看到整个序列里面所有的元素
但是对解码器来讲
因为有研码的存在
所以它在对第二个元素抽特征的时候
它只会看到当前元素和它之前的这些元素
它后面那些元素的东西通过一个研码
使得在计算注意力机制的时候变成0
所以它是不看后面的东西的
这个地方因为我们用的是标准的语言模型
我们只对前预测
我们预测第二个词的时候
不会看到这个词后面的这些词是谁
所以一定是往前的
这个地方所以我们只能使用Transformer的解码器
而不能使用它的编码器
然后下面它给了稍微这个模型的一些解释单
假设你对Transformer比较了解了
它说如果我要预测u这个词它的概率的话
那我们把这个词前面这些词全部拉出来
就kx拉出来积成一个大u
然后把它做一个投影
就此前路的投影
再加上一个位置信息的编码
那得到你的低层的输入
那么接下来我要做n层这样子的Transformer快
每一层我们把上一次的输出拉进来
然后得到输出
因为我们知道Transformer快
不会改变你的输入输出的形状
所以你一直做完之后
最后拿到你最后一个Transformer快的输出
然后再做一个投影
用softmax就会得到它的概率分布了
如果大家忘记了Transformer快是怎么定义的话
欢迎回到我们之前Transformer这篇文章的讲解视频
里面有详细的讲解
因为我们已经读过了Bird这篇文章
我们稍微来讲一下它跟Bird的区别
Bird我们知道它用的不是标准的语言模型
它用的是一个带研码的语言模型
它就是完心填空
所以完心填空是说我给一个句子
我把中间的一个词挖掉
让你预测中间的
就是说你在预测的时候
我既能看见它之前的词
又能看见之后的词
所以它可以对应的使用Transformer的编码器
因为编码器只能看到所有
所以使用编码器和解码器
倒不是它们两个的主要的区别
主要的区别在于你的目标函数的选取
这个地方GPT用的是一个更难的
就是给前面一段话预测后面一个词
预测未来当然比完心填空要难
具体来说我给你股票的信息到当前的股价
之前都知道我让你预测明天的股价
远远的难于是说
我告诉你到今天为止的股价
但是我昨天的股票不告诉你
然后你预测昨天这个股票的价格
你都知道过去和未来
那么中间差池就能得到中间
就是预测一个开放式的结局
比预测中间一个状态要难很多
这也是导致的GPT在训练上和效果上
它其实比Bert要差一些的一个原因之一吧
那么反过来讲
如果你的模型真的能预测未来的话
那么你比Bert这种通过完心填空训练模型
要强大很多
这也是为什么作者需要
一直不断的把模型做大
而且一直不断录制
才能最后做出GPT3那样子效果精硬的模型出来
这也是我们之前讲到的
作者选了一个更难的计时互现
但很有可能他的天花板也就更高了
所以这就是预训的模型
这也是为什么我们说
GPT就是穿format的一个解码器
简单来讲就是这么回事对吧
接下来我们来看一下它是怎么样做微调的
在微调任务里面我是有标号的
具体来说每一次我给你一个常为m的一个次序列
然后我告诉你这个序列它对应的标号是y
那么就是说我们每一次给这个序列去预测它的y
具体来讲就是说我每次给你x1一直到xm
我要预测y的概率
它这里的做法是把整个这个序列
放进我们之前训练好的GPT的模型里面
然后拿到transformer快的最后一层的输出
它对应的hm这个次的这个输出
然后再乘以一个输出层
然后再做一个softmax就得到它的概率了
这是微调任务里面所有的带标号的这些序列对
我们把这个序列x1到xm输入进去之后
计算我们真实的那个标号上面的概率
我们要对它做最大化
这是一个非常标准的一个分类目标函数
然后作者说虽然我们在微调的时候
我们只关心这一个分类的精度
但如果把之前的这个语言模型
同样放进来效果也不错
意思是说我们在做微调的时候
有两个目标函数
第一个是说给你这些序列
然后预测序列的下一个词
和给你完整的序列
让你预测序列对应的标号
这两个一起训练效果是最佳的
然后它通过一个numda把这两个目标函数加起来
最后这个东西是可以调的了
也是一个超参数了
那我们知道微调长什么样子的情况下
接下来要考虑的是
怎么样把NLP里面那些很不一样的子任务
表示成一个我们要的形式
就是说表示成一个序列和它一个对应的标号
那就是第三点三小节要讲的事情了
我们可以直接通过图1
就能给大家讲清楚到底是怎么表示的
这里给了NLP里面四大常见的用
我们下面来看一看他们都是什么
第一类是最常见的分类
就是说给我一句话或者一段文本
我来判断它对应的一个标号
比如说一个用户对一个产品的评价
是正面的还是负面的
它这里的做法是说
我把我要分类的这一段文字
在前面放一个初始的词源
在后面加一个抽取的词源
然后就做成一个序列
序列放进Transformer的解码器里面
然后模型对最后一个词它抽取的特征
放进一个线性层里面
线性层的话就投影到我要的那个标号的空间
就是说如果我要做十类分类的话
那么你的线性层它的输出大小就是10
在训练的时候就是对每一个文本和标号对
我们把文本编成一个这样子的序列
然后标号就放在这个地方参加训练
在预测的时候当然是说
我们只拿到这个序列信息
然后对它直接做预测就行了
所以这个地方跟之前的预言模型
还是有那么一点区别的
因为这个线性层是我新加的
就是在VTI的时候
我重新构造了一个新的线性层
里面的权种可能是随机输出化的
然后它的输出大小跟我的标号的大小是一致的
第二个应用叫做蕴含
就是说我给你一段话
然后再问你一个假设
你看一下我前面这段话
有没有蕴含我假设提出来的东西
比如说A送给B一束玫瑰
假设我的假设是说A喜欢B
那么你就说我前面这段话是支持你这个假设的
如果我说A讨厌B
那么你可以认为前面这段话是不支持这个假设的
如果我说A和B是邻居
那么你可以说前面这个假设
它既不支持也不反对我这个假设
所以说白了就是一个三类的问题
我给你两段文本
然后让你做一个三分类的问题
它在表达的时候
就是把这两个文本串成一个长的序列
用一个开始符在这个地方
分格符和抽取符
当注意到我们这里写的是star呀
分格呀和抽取
但是在真实表达的时候
你不能用这个词放进去的
是因为这些词可能在文本里面也要出现
所以这三个词源是一个特殊的记号
跟我的词典里面那些别的词是不一样才行的
不然的话模型就会混淆了
第三个应用是相似
就是判断两段文字是不是相似
这个应用在NLP里面用的也是非常广泛
比如说我一个搜索词和我一个文档是不是相似的
或者说我两个文档是不是相似
我这样子能来去从
或者说我两个问题问的是不是相似来去从
因为相似是一个对称的关系
就说A和B相似
那么意味着B和A也是相似的
但是我们在语言模型里面是有个先后的顺序
所以这个地方它做了两个序列
第一个序列里面第一段文字放在第二段文字前面
中间还是一样用分割幅分开
前面加一个起始幅和一个结束幅
第二个序列就是把文字一和文字二交换顺序
第二个序列就是把文字一和文字二交换顺序
这是因为它的对称关系
然后这两段序列分别进入我的模型之后
得到最后的这个输出
然后在上面做加号
最后进入我的线性层得到我们要的是相似
还是不是相似的一个二分人的问题
最后是一个多选题
就是我问你一个问题
然后给你几个答案
你在里面选出你觉得正确的一个答案
它的做法是如果你有N个答案的话
那我们就构造N个序列
其中前面的都是你的问题
然后每一个答案作为第二个序列放在这个地方
每一个序列分别进入你的模型
然后用一个线性投影层
它的输出大小是1
再得到你这个答案是我这个问题
问到的正确答案的一个执行度
对每个答案我都算一个这样子的标量
然后最后做一个softmax
就知道我对这个问题
我对每个答案觉得是它正确答案的执行度是等于多少了
可以看到虽然这些应用上
它的数据都长得不那么一样
但是基本上都可以构造成一个序列
要么就是有一段话
要么就是有两段话
但是分隔开来
如果更复杂一点的话
我可以构造出多个序列出来
但是这个地方不管我的输入形式怎么变
我的输出它的构造怎么变
中间这个transformer模型是不会变的
就是说我预训练好我的transformer模型之后
我在做下游的任务的时候
我都不会对这个模型的结构做改变
这也是GBT跟之前工作的一个大的区别
也就是这篇文章卖的一个核心点
展完模型之后
我们来看一下它的实验
实验我们这里不会仔细给大家讲
大家只要注意到这有两点就是了
第一点是它是在一个叫做Book Corpus的
一个数据机上训练出来的
这个地方有7000篇没有被发表的数
第二个是说它的模型的大小是长成这个样子的
它用了12层的一个transformer的解码器
然后每一层的它的维度是768
所以我们关心的是说
你用一个多大的模型
在一个多大的数据机上训练好的
在结果上它当然比了之前那些算法
它说我们这样子的方法比前面的人都要好一点
这个是GBT这个算法
然后加黑是表示我在精度上都比别人高
这个是那么几个数据机上面基本上都是比前人高
然后我们再回过头来看一下
我们之前讲过的Bert这篇文章
注意到这个论文就换成Bert了
这个地方是Bert
看到Bert的base它用的是12层
它的维度也是768
所以Bert的base就是为了跟GBT做对比的
虽然Bert用的是编码器
GBT用的是解码器
编码器在同样的层速和维度大小的时候
它比解码器其实那么简单一点点
因为它少一块带研磨的那个模块
但是基本上你可以认为它也是差不多等价的
所以Bert的base做的就是为了跟GBT对比
然后你看BertLarge它的层数翻了一倍
然后它的宽度翻了1.3倍
然后最后你的BertLarge是你的BertBase的
基本上复杂度是差不多三倍的样子
那为什么你可以做三倍呢
是因为Bert用的数据集更大一些
这个地方讲的是Bert他用的数据集
他用了GBT的那个book corpus的数据集
那就是它这里使用的是词的个数
是用了8亿个词
然后他还用了一个基本上是三倍
大约20亿个词的VKP的数据集
所以Bert的整个数据的大小
基本上是GBT用的数据集的
大概四倍的样子
所以他在这个数据集上训练了一个
比GBT大三倍的模型
那也是可以理解的
然后再回过头来看一下Bert的实验
这个地方比较了是GBT
然后BertBase虽然跟你GBT的模型是差不多
但实际上在整个的平均的精度上
还是要比它好一点
你看它是75.1
那Bert做到了79
然后如果你把模型做更大的话
它还能从79.6提升到82.1
这也是对我们之前讲过的Bert
一个非常简单的回顾
好 接下来我们来看一下GBT2
就当你发现你的工作被别人用
更大的模型 更大的数据集打败的时候
那么你怎么样去回应
GBT2这篇文章它的标题叫做
语言模型是无监督的多任务学习器
我们等会来看多任务学习器是什么意思
当然无监督我们理解
语言模型我们理解
作者上一作没有变换
最后一个作者也没有变换
之前GBT那篇文章中间是有两个作者
现在全部换掉了 换成了四个作者
就是说主力干活的作者还是
大老板也没有变
但是队员就换了一波
就在看摘要之前大家想一想
如果你说我用一个解码器
训练一个很好的模型
效果非常好 觉得自己棒棒的
但是几个月之后被人用一个编码器
用一个更大的数据集
训练一个更大的模型打败了
那你心里怎么想
那你得打回去 对吧
首先你不能换你的解码器了
因为你已经站好队了
如果你再换回编码器
说编码器真的好
那么你前面的工作就浪费了
所以因为一作没有变
所以技术路线是不能变的
我还是要认为解码器好
那么怎么打回去呢
很简单
我可以把我的模型做得更大
数据做得更大
但如果我通过做更大
就能把前面的工作打败的话
那么我写文章也没什么问题
但问题是在于
如果你变大了
但是你还是打不赢打你的那个工作的话
那么你怎么办呢
这就是GPD2这个工作要面临的情况
我们可以大概看一下
首先它做了一个新的数据集
叫做web text
然后有百万级别的文本
那么跟之前的wikipedia和book corpus
那么当然这个数据集要更大了
你有了更大的数据集之后
你能干嘛
那就可以训练一个更大的模型
15亿个参数的transformer
记得bertlog
他最大只是3.4个亿
现在直接跳到了15亿
那就是说你的文本变成了百万级别的文本
那么你的模型变成了10亿级别的模型
但可惜的是说
当你变得那么大的情况下
你发现跟bert比可能优势并不大
这时候作者就找了另外一个观点
叫做ZerShot的一个设定
他其实在GPD那篇文章的最后一节有讲
他用ZerShot来做一些实验
主要是去了解整个模型的训练的机制
在GPD2这篇文章就把ZerShot作为他的一个主要的卖点
拿了出来
我们这篇文章主要看一下是他怎么去卖ZerShot这个事情呢
在导演里面
作者说现在一个主流的途径就是对一个任务收集一个数据集
然后在上面训练模型做预测
为什么这个东西很流行
是因为现在的模型它的泛化性是不是很好的
就是说你在一个数据集
一个应用上训练好的模型
很难直接用到下一个模型上面
然后他又提到叫做多任务学习
多任务学习一开始的观点是说
我在训练一个模型的时候
同时看多个数据集
而且可能会通过多一个损失函数
来达到一个模型能够在多个任务上都能用
这个是在90年代末提出来的
在2000年到2010年之间
也曾经是比较流行的一个话题
作者说虽然这个东西看上去比较好
但是在NOP里面
其实用的不多
在NOP里面现在主要的算法
也就是之前GPD-1和Bert那一类的
就是说在一个比较大的数据上
做一个预训的模型
然后在对每个任务上
做一个有监督的微调
当然这样子还是有两个问题
第一个是说对每一个下游的任务
你还是得去重新训练你的模型
第二个是说你也得收集有标号的数据才行
这样导致你在拓展到一个新的任务上
还是有一定的成本的
然后捣乱的最后一段话
就是说GPD-2要干什么事情
他说我还是在做我的语言模型
但是我在做到下游任务的时候
我会用一个叫做zero short的设定
zero short是说我在做到下游的任务的时候
不需要下游任务的任何标注的信息
那么当然也不要去训练我的模型
这样子的好处是说
我只要训练一个模型
在任何地方都能用
最后一句话是说
我们得到了还看上去挺不错的
而且有一定竞争力的结果
回到我们前面讨论的
如果作者就是在GPD的基础上
用一个更大的数据集
训练一个更大的模型
说我比Bert好一些
可能也就好那么一点点
不是好那么多的情况下
那么这篇文章有没有意思
大家会觉得没什么意思
工程位特别重
那么现在来了
我换一个角度
我选择一个更难的问题
我说做zero short
就不训练
不要下游任务的任何标号
然后给你得到也还不错
差不多的
有时候好一点
有时候差一点的结果
虽然这个时候
从结果上看没那么厉害
但新一度一下就来了
对吧
所以这也给大家做研究
有一些提示
你不要一条路走到黑
做工程你可以一条路走到黑
你就把精度往死里做
但是在做研究的时候
你一定要比较灵活一点
尝试从一个新的角度来看问题
接下来我们来看一下方法第二节
因为GBD2和GBD1在模型上
基本上是长得一样的
所以我们不给大家一段一段读了
而是给大家讲一下
跟之前方法的一些不同的地方
在什么地方
回忆一下
我们在之前做GBD的时候
我们在预训练语言模型的时候
是在自然的文本上训练的
但是在做下游的任务的时候
我们对它的输入进行了构造
特别的是说
我们加入了开始符
结束符和中间的分隔符
这些符号在之前模型是没有看过的
但是因为你有微调的环节
所以模型会去认识这些符号
你给我一些训练样本
我去认识这个符号
代表什么意思
但现在你要做zero short
那你的问题是什么
你在做下游的任务的时候
我的模型不能被调整了
但是如果你还引入一些
模型之前没见过的符号的话
模型就会感到很困惑
所以在这个设定下
我们在构造下游任务的输入的时候
就不能引入那些模型没有见过的符号
而是要使得整个下游任务
它的输入跟你之前在预训练模型
看到的文本长得一样
就是说你的输入的形式
应该更像一个自然的语言
这个地方作者给了两个例子
第一个例子是说做机器翻译
如果你一下把英语翻译成法语
你可以表达成这样一个句子
首先是翻译成法语
给你英语的那个文本
然后接下来是你英语对应的法语的文本
所以前面这三个词
你可认为就是做了一个特殊的分割符的意思
在后面的文献里面
这个叫做prompt
也叫做提示
就如果你要做阅读理解的话
它又说我可以设计一个提示
叫做回答这个问题
接下来是你读的那个文本
然后是你的问题
最后是你的答案
这个地方回答这个问题
作为一个提示
让模型知道我现在要去做这个任务
接下来还有大量的讨论
你为什么可以这么做
因为这个东西不是作者提出来
是前面的工作
这篇工作提出来的东西
后面这些话
基本上作者都在讨论
是说这个途径到底为什么可以工作
作者觉得如果你的模型足够强大
它能理解你的提示符干的事情
那当然就比较好
另外一个是说
可能在文本里面
这样子的话也很常见
可能本来就出现在这里面
那么它在下面一节讲数据那一节
稍微对第二点做了一些解释
我们来看一下它的训练数据
长什么样子的
这一节里面它详细讲了一下
它的数据是怎么样出来的
首先第一段话说
前面人大家用Bert用的Wikipedia
那么他们自己用的是书
那么接下来你要构造一个
更大的数据集才行
它说一个可行性的办法
需要一个叫做comicraw的一个项目
comicraw是一个公开的网页抓取的项目
就有一群人写了一个爬虫
然后不断的去在网上抓取网页
然后把抓取的网页放在AWS的S3上面
然后供大家免费的下载
这个项目已经做了很多年
目前来说应该是有TBG的数量级
应该是目前能够很方便下到的
最大的一个文本数据集
作者说这个数据集不好用
这是因为它的性造比比较低
因为抓回来的网页里面很多
可能是没有含有比较有意思信息的
可能就是一些很垃圾的网页
那么你要怎么去清理它
需要花很多很多的时间
就说虽然我没有能力现在把你很好的标出来
但是它可以去利用网上大家已经过滤好的一些网页
具体来说它用的是Reddit
Reddit是一个美国排名很靠前的一个新闻聚合网页
在国内好像没有类似的一个服务
它的想法是说每个人可以去提交你感兴趣的一些网页
然后把你分门别类的放在每一个类别下面
接下来Reddit的用户就是对你投票
说喜欢或者不喜欢
然后给它进行评论
然后你投票的话会产生一个叫做Karma的一个东西
它最早来源于佛教里面的一个术语
当我不是专家
你大概可以理解成一个轮回报应值
在Reddit上面Karma你可认为是用户对一个帖子的一个评价
然后它选取了所有至少有三个Karma的帖子
Reddit的用户已经帮你图扣
而且觉得里面有一定的价值
然后它去把它所有的爬下来
最后得到了4500万个链接
然后再把它里面的文字信息给你抽取出来
就这样子得到了一个数据集
这个数据集最后大概是800万个文本
然后一共是40GB的文字
然后在表一里面它又拎了一些句子出来证明说
其实在我爬下来的数据里面
就是对于英语翻法语这个例子来讲
已经有了很多的这样子的样例
比如说这句话是说
有人写了在法语里面写了一句这样子的话
然后如果翻译成英语来说
那就是长这样子
下面都是说这些都是怎么样对应的英语语句
翻译成法语长什么样子
作者想表达意思是说
如果你在这样子数据上面训练语言模型的话
很有可能它确实就可以真的把英语翻译成法语
因为你的文本里面出现过很多这样子的例子
当你有了更大的数据集的时候
你当然可以把模型做得更大了
作者一共设计了四个模型
第一个模型有12层
每一层它的宽度是768
一共有1亿个可学习的变量
那么就是来自于之前的GPD或者BertBase
第二个模型就是BertLog了
然后它在之上最大的情况下是说
它把乘数再翻了一倍
就是24变成了48
然后你的宽度也从1024变成了160
基本上是1.5倍的样子
得到了一共有15亿个可学习元素的模型
就后面一些实验
我们就没打算给大家仔细的去过
因为它的实验主要是跟别的做ZierShot的方法比
会长什么样子
比如说在这个地方
你看到的是它的这四个模型
跟当前在不同这些任务上面的ZierShot的SOTA
它的方法的比较
这些方法不是我们之前讲过的Bert那一类
还是说专门做ZierShot那一类怎么样
当然是说GPD我们比你们多好
因为你用到的模型复杂度和数据量
确实比人家甩出几条街出来
在最前面其实有一张表
显示的是它在几个任务上面的一些体现
比如说这个是你的阅度理解
翻译摘要和问题回答
下面你的走分别是你的模型大小
因为它这个地方有四个模型
所以它一共有四个点
然后这个地方你看到阅度理解上来说
它似乎跟别人还是不错的
就是说这个是比较好的方法
摘要上面就差一点
这个是sequent to sequent
加上注意力机制的一个模型
还差一点
如果你在QA上面
那就是你跟现在的别的好模型差得远
因为现在别的好模型
还在远远的上面很远的地方了
所以你还早的很
所以也就是说在摘要里面
作者说虽然我们的结果还是比较有意思的
在一些任务上还做不错
另外一些任务上是有那么一点的意思
所以他讲的也是比较委婉
但是注意到是说
随着你的模型的增大
你的性能还是在上升的
也就是说你还是有希望
训练更大的模型
使用更大的数据机
使得你的模型的性能能够突破天际
使得跟真正的在有监督上面
训练出来效果是一样
这就是接下来工作GPT3样干的事情
这样我们就快速的过了一下GPT2这篇文章
然后接下来我们来看GPT3这篇文章
GPT3这篇文章的标题叫做
语言模型是FuShot Learner
在讲GPT的时候
我们有讲过他在文章的最后一段
其实也做了一些实验
就是在子任务上面
我给你提供一些样本
但是不是在职务上所有的样本的时候
其实语言模型能够用最少数的样本
能极大的提升性能
GPT2是在GPT上往前走了一大步
是说在子任务上面
我不给你提供任何相关的训练样本
直接使用预训练的模型
去对子任务上做预测
作者之所以这么做很有可能
就是为了跟Birds这篇文章
在新一度上能够有所区分
我们有讲过一篇诺文的价值
取决于你的新一度要诚意你的有效性
当然要诚意你问题的大小
但是不管是GPT还是Birds
他做的是同样的问题
所以问题的大小是固定的
GPT2虽然在新一度上拉得特别高
但是有效性比较低
所以导致它论文的价值
最后很难说是一篇特别重要的文章
所以GPT3就是尝试去解决GPT2的有效性
所以它又回到了GPT一开始考虑的
Fuel short设置
就是说我不再去追求很极致的
我在一个子任务上不给你任何样例
其实在现实生活中也很少
就算是人类你要学习的时候
你也要通过一些样本来学习
只是说人类在样本的有效性上做的比较好
就通过一点点样本就行了
但是语言模型需要大量的样本
所以在这里Fuel short的意思是说
我还是给你一些样本
但不用太多
只要你的样本的个数是在可控的范围里面
所以这个成本还是非常低的
在作者上面
可以看到作者基本上换掉了
GPT和GPT2的一座已经跑到了最后
前面的这些作者其实之前基本上都没有出现过的
当然如果大家感兴趣的话
可以跳到文章的末尾
它有详细的解释了每个作者是干了什么事情的
我觉得GPT3这篇文章的一大贡献
真的就是虽然我挂了很多作者的名字
但是我还真后面解释了每个作者干了什么事情
也是给大家一个标杆说
你可以写很多名字没关系
但是你至少告诉我说这些人真的是干的活
不是就是上面挂个名字来撰一个引用了
而且大家如果去仔细看的话
基本上看到前面这些作者
基本上都是在做实验的上面
GPT3这篇文章真的是做了特别特别多的实验
这也是整个OpenAI它做文章的一大特点
就如我们之前讲的Clip这文章
它也是做了大量的实验
所以导致有大量的作者
接下来我们来看一下摘要
摘要的前面几句话没有什么特别好看的
就跟之前没有什么太多区别
具体来看到是说我们训练了一个GPT3的模型
这也是一个自回归模型
但是它有1750亿个可学习的参数
比之前所有的那些非西数的模型
西数的模型是说你整个群众可以是西数的
里面有大量的零
但如果你的模型有很多很多零的话
你把这些零算进去的话
你的模型给算的特别大
所以它作为对比它跟那些非西数的
就是说不会存在很多零的这些模型相比
它比它要大10倍
就是在可学习的参数上面
然后因为你的模型已经那么大了
那么在做子任务的时候
你如果还要去训练你的模型的话
那么你的成本上是很难的
所以在这个地方
GPT3在作用到子任务上面时候
不做任何的T度更新或者是微调
就算是在Fuel short的情况下
给你一些样本情况下
GPT3也不是用微调
因为微调需要你总是去算T度
那么大的模型算T度是非常非常难的事情
所以这个地方它是不做任何的T度更新的
也是它的一大特点
然后它说我在所谓的这些LMP的任务上
取得了很好的成绩
这也是跟GPT2它能区分开来
GPT2它的成绩跟我们想要的还差得很远
然后最后作者说GPT3能生成一些新闻的文章
而且人类读起来是很难区分
看你到底是模型生成的还是人类写的
这也是GPT3的一大卖点
也就是后面大家能通过它玩出花样来的一个主要的地方在这个地方
还有这就是摘要
就是说GPT3特别大
在做植物的时候不需要算T度
这是因为它特别大
而且它的性能特别好
这是它想要表达的东西
接下来是它的目录
这也是我们第一次读到在论文的第二页放目录的文章了
然后可以看到前面两节是讲它的方法
写了十页
然后是它一个长长的结果
它又写了十页
在后面是一个长达二十页的一个讨论
在讨论之后还有一个二十页的复录
里面讲的是一些细节
所以整个文章有63页
它不是一篇投稿的文章
而是一个技术报告
所谓的技术报告是讲没有发表的文章
因为它没有版面和页数的限制
你可以写得特别长
当然长有长的好处
它可以把东西写得特别细
所以你在读它的时候
可能没有相关的背景知识读起来也没问题
但是长的坏处是说你的阅读门槛又增加了
如果我就想了解一下你做什么事情
我要读63页
那么我怎么读
但这个地方我的个人看法是
GPT3真的没必要写那么长
它写那么长
它并没有把前面的东西交代的特别详细
也就是为什么我们在讲GPT3之前
需要给大家讲一下什么是GPT和GPD2
因为这两篇文章的内容
在GPT3这篇文章里面是没有覆盖的
就是说虽然我写了63页
但我并没有讲前面两个工作什么东西
而且GPT3是完全基于GPD2这个模型的
63页并没有讲这个模型
而是它花了大量的篇幅去想这种结果和后面那些讨论
所以导致说在读63页的论文之前
我们先得把前面两个论文给读了才行
所以我个人是非常不推荐大家这种写法
你要么就写得短一点
大家读下来很快就知道你的中心思想
要么你就写得长一点
把前面的背景知识给大家详细的介绍一下
我不需要读前面的文章
从你这篇文章开始我也能知道你在做什么
像这种你既需要读前面文章
又需要读我很长的文章
只有当你的工作是真的是特别特别好的时候
你才可以那么任性
别人才会来读你的文章了
我们接下来看一下导研
导研的第一段话是说
最近一些年来NLP里面大家都使用预讯念好的语言模型
然后再做微调
第二段话是说这当然是有问题的
它是什么问题呢
它说我们对每个子任务
还是需要一个跟任务相关的数域级
而且要跟你任务相关的一个微调
具体来说它列了三个问题
第一个问题是说你需要一个大的数域级
你得去标号吧
这当然是有问题的
GPT-2也讲到这个事情了
第二个我觉得就相对来说比较虚一点
就是说当你的一个样本
没有出现在你的数据分布里面的时候
你泛化性不见得就比你那个小模型要好
所以是说如果你在微调上面的效果很好的话
也不能说明你的预训练的模型它的泛化性就特别好
它很有可能就是你过你和你的预训练的训练数据
而且这个训练数据跟你的微调所要的那些任务
刚好有一定的重合性
就导致你在这些微调任务上是做得比较好的
就跟之前用书来做预训练
用Wikipedia做预训练
或者是在网上爬的网页做预训练
这些文字里面刚好包括你所有下游任务它要的那些文字
它们都是类似的一些文字
所以导致你的微调效果比较好
但是如果你换到一个别的语种
或者换到一个更专业性的文本上面
你的表现力可能就不那么的好了
所以作者在这里的意思是说
假设我不允许你做微调
不允许你改变你预训练模型的参数的话
那么你就是真的就是拼着预训练模型的泛化性
假设我允许你微调的话
那么预训练模型可能好一点坏一点
它都差别不那么大了
第三个是说人类
大家都会说到人类
人类不需要一个很大的数据机来做一个任务
就是说你又一定的语文功底的话
我让你做一个别的事情
你可能给你两个例子
告诉你怎么做就行了
你不需要再采集成千上万
就你不要做个基本CTT才会掌握一个小应用了
当然然后作者提出这个问题之后
要讲他的解决方案
他的解决方案也跟之前讲过
他其实也就是做fuel short或者zero short的学习了
在这个地方作者他又换了一个名词来了
他说一个解决这个问题的办法叫做meta learning
叫做原学习
我觉得作者在取名字这个事情上
也不见得是那么的精确
就是跟GPT-2用的是multi-task多任务学习
但是它其实跟之前的multi-task learning
还是有那么一点点区别的
然后在这个地方他又试图去重新定义什么叫做meta learning
他有一个注释
有一个长程的注释讲了说
我们跟之前大家叫的meta learning
当然是有一点点不一样了
所以这个地方我们有我们自己的定义
但我觉得你如果想重载前面大家都知道的一些名字的话
除非有特别多的必要
不然没意义
因为你会给大家造成误解
而且大家现在讲到GPT-3这篇文章的时候
也不会去提它是用的是meta learning
或者是它是用的是multi-task learning
然后他当然在后面又定了一个名词叫做incontent learning
就是在上下文之间的学习
虽然用的是zero short和fuel short
他在这个地方在jio上面已经讲过
我是不更新我的模型的
因为在计算机视觉里面
我们有讲zero short
zero short好理解
那我什么都不干没关系
但是作于fuel short的话
我给你一些样本的话
我还是可以用这些样本来对我的模型进行更新
这样子我能够更理合到这个上面去
但他这个地方他强调的是
我不要对我的权重做任何的更新
因为你的模型太大了
更新不了
所以他这个地方需要跟前面做区分开来
所以他尝试的用了两个名词在这个地方
一个是meta learning
一个是incontent learning
但是大家理解一下他讲什么就行了
所谓的meta learning就是我真的训练一个很大的模型
里面的繁华性还不错
incontent learning是说我在后面的时候
即使告诉我一些训练样本
我也不更新我的权重
他在前面有画一个图
就是图1上面有讲了一下meta learning的大概一个想法
他这个地方画的是有一点点的奇怪的
他看上去好像是讲我的模型是怎么训练的
就是说我有一个通过SGD来做预训练的过程
然后在每一步里面好像要做一个什么样的事情
他其实他不是真正的讲GPD3这个模型怎么训练出来的
而是说这个语言模型
你可以怎么样类比成一个meta learning
他是说如果你这一个是一个样本
这也是一个样本
而且每个样本来最不同的文章的时候
可能他要干的事情不一样
比如说这一个样本
这一段话告诉你的是各种加法怎么做
就下面的话告诉你是一个错别字
怎么改成一个正确的
然后再后面就是英语翻成法语
所以说在每一个段落或者每一个文章
如果来自很不一样地方的时候
他可能教你不一样的东西
如果你在大量的这种很多样性的文章上做训练的时候
你的模型多多少少有在做一个原学习的过程
就是他学习的大量的任务
而且每一个段落
你可以认为是一个叫上下文的学习
因为他们之间是相关的
然后你从上下文来得到一些信息
但是他们之间他就没有太多关系了
就是多个任务之间了
所以这个东西放在这里
其实放不放我觉得他都不影响到他的模型的
但是放在这里我们就讲一下
但是大家如果一开始读的时候读得有点奇怪
可以忽略也不要紧
然后再讲了他的设定之后
他又说最近线连大家的模型的大小变得越来越大
但是其实我觉得也就是OpenAI
把整个军备竞赛给大家搞了起来
像GPT31出来大家都觉得你可以做那么大
然后别的公司也纷纷的跟进
不管是美国的还是国内的公司
大家也愿意去参加这样子的比赛
然后在后面也是说GPT3是一个1750一个可学习参数的模型
然后他的模型他的评估是用了这三个办法
一个叫做fuel shortening
也就是说对每个子任务
我给你提供大概10到100个的训练样本
那么他的一个特殊的情况叫做one shortening
就是每一个任务我只给你一个样本
就是说英文翻法语的时候
我就告诉你一个
英文hello world怎么翻成法语的那个词
然后让你接下来给我继续翻下去
那么接下来是zero short
就是说我一个样本都不告诉你
我就让你英语翻法语
然后他在一开始给大家了一张图
给大家展示了一下
在三个设定下他的模型的一个区别
他的x走在这个地方
是整个语言模型可学习参数的大小
这1.3b基本上就是GPT2的模型
然后你的y走是你的accuracy
当然你在很多指认物上面
他做了一个平均
就是这些虚线是每一个指认物上的
然后他做平均就变成了三个实线
然后这里有三条线
颜色不一样的线
黄色表示的是fuel short
绿色表示的是one short
蓝色表示的是zero short
之前我们讲过的GPT2这笔文章
你可以认为就是1.3b这个模型
然后用zero short
那么精度可以认为平均下来是30%左右的样子
然后你把1.3b变成了175b的时候
就这个点的时候
而且使用了fuel short
就允许给你10到100个样本的时候
那么基本上看到它的精度接近了60%
就是基本上你的精度翻了一倍了
所以可以看到效果还是非常明显的
好 这就是他的导验
接下来我们来看一下第二章
也就是他的模型的部分
在模型的部分
他先给大家又重新讲了一下
什么叫做fine tuning
然后他的fuel short learning
和他one short
以及他的zero short
他到底是什么区别
但其实你在这个地方
你可以通过下面这个图是看得比较清楚的
首先右边讲的是微调是怎么做的
在微调的时候
我们训练好预训练模型之后
在每一个任务上面
我们提供一些训练样本
然后这个地方
假设我使用批量大小为一来训练的话
就每次给你一个样本
这个是英语翻法语的样本
因为我有标号
所以我能计算损失
然后我就可以去对他的全中进行更新
然后再拿到一个新的样本继续更新
就可以当做一个很正常的训练任务来做
但是跟之前不一样的是说
微调通常对数据量的要求要少于从零开始训练
而且在学习率上通常可以做的比较小一点
这是因为微调的初始值
那个模型是用预训练好的模型做的
所以它跟你最终的解已经很近了
所以你知道大概稍微调一下就行了
但是在GPT-3模型的设置里面
它追求的是不做T2更新
当然不做模型更新
它肯定是有它的新异度的
但反过来讲那么大一个模型
假设我换到一个新任务上
还得再做更新的话
那么它的使用门槛是比较高
所以也不可能使得像现在那样
大家可以在GPT-3上面玩出花来
它这里使用的是英语翻法语这个例子
它想干的事情是说
把英语的cheese翻成法语的对应的单词
假设在Zero short里面怎么办
它就在前面加一句说
把英语翻成法语
然后冒号
这是你这个任务的描述
当然它希望你预训练好的GPT-3模型
能理解这句话是想干什么事情
然后是把我要翻译的词放进来
加一个箭头
箭头这个东西叫做prompt
也叫做提示
告诉你这个模型说
好 接下来就是轮到你输出了
然后把这句话放进模型
模型对下一个词的预测这个词
那就应该是cheese它对应的法语的单词
如果你对了
那就对了
如果错了
那就是你模型预测错误
如果需要one short怎么做呢
就是在你任务描述之后
和在你真正的做翻译之前
我插一个样本进来
就是在定义好这个任务之后
我再告诉你一个例子
英语单词翻成法语单词
应该是这么翻译的
就希望你这个模型在
看到整个句子的时候
能够从这条里面提取出有用的信息
来帮助你做后面的翻译
注意到这一点是说
这是一个样本放进去的
它只是做预测
它不做训练
就是说虽然它是一个训练样本
但是它放进之后是不会对模型算梯度
也不会对模型做更新
所以它希望的是
你在模型在做前项推理的时候
能够通过注意力机制
然后去处理比较长的序列信息
从中间抽取出来有用的信息
能够帮助你下面做事情
这也是为什么叫做上下文的学习
就是你的学习只是限于你的上下文
那么fuel short的能力
就是对one short的一个拓展
就之前我是给你一个样本
现在我可以给你多个样本
当然你可以做更长
但是更长不一定有用
因为你这个模型
不一定能处理特别长的数据
就是说如果你的序列很长的话
那么模型也不一定有能力
把整个句子里面的信息给你抽取出来
然后让你帮助到生成做这个事情
所以看完这个图之后
大家就知道这两种模式之间的区别
GPT-3采用的这个序列
当然是对新的人物更加友好了
就是说我碰到一个完全之前没见过的任务的话
我不要去更新我的模型
因为做模型的推理和做模型的训练
在你的设置上是很不一样的
因为在训练的时候
我对内存的要求更高
而且有操场数要调
而且得很好的准备你的训练数据
但现在我只要做预测就行了
哪一个新任务给你
你把结果返回给我就行了
这当然是它的好处
当然也有一点点坏处
坏处是说
假设我真的有很多训练样本
那怎么办
比如说我就做英语到法语的翻译
大家很容易在网上找到个几百上千个样本
来帮助你翻译 对吧
这个时候你发现你想放进去
是很难的一件事情
难道你要构造一个样本里面
把整个子人物的训练数据放进去吗
那么就是特别长
你可能模型处理不了
第二个问题还是相关的
就是说我假设有一个还不错的训练样本
然后你的模型在不给你的训练样本的时候
表现不行
我需要给你个训练样本
但是每一次我都给你
就每一次做一个新的预测的时候
我都把你给你
因为你这个模型是每一次的时候
要从中间去抓取有的信息
就我不能把上一次模型从中间抓取的信息
给你存下来存到你这模型里面
所以这也导致说
虽然GPT-3在一年半前就把这个效果做得那么好
但实际上好像用FuShot做这种上下文的学习
似乎用的还不那么的多
2.1节讲的是它的模型和架构
它说GPT-3的模型跟GPT-2的模型是一样的
后面补充了GPT-2模型跟之前GPT的区别
是你的模型的初始改变
把你的normalization放到了前面
和可以反转的词源
但是也做了一点的改动
具体来说它就是把Spot Transformer这个工作
里面的那些改动给你拿了过来
然后它设计了8个不同大小的模型
具体来说可以看在表2.1里面讲了
这个表里面每一行表示的是一个模型
每个列能表示的是模型的一些参数
比如说这个列表示的是你模型里面
有多少个可以学习的参数
然后你这个模型里面有多少层
然后你每一层的词表示成一个多么长的向量
以及在多头注意力里面有多少个头
最后是你每个头的那个维度的大小
它就是等于你这个D Model处于你N Heads
Batch Size是说在训练的时候
每一个小批量大小多大
最后是你在训练的时候用的学习率是多少
首先看一下第一个模型
第一个模型是GPT-3 Small
可以看到它一是二层
每一层大小是768
是不是很熟悉
它就是GPT模型它的参数是这样子的
然后它的可学习参数是1.25个亿
也是Bert Base它的模型的大小
GPT-3 Medium 24层
每一层大小是1024
然后大家知道这个尺寸是BertLarge的尺寸
然后在后面几个模型
就是乘速没有变
但是你每一层的宽度有增加
然后看到1.3B这个模型
虽然之前我们在讲图画的时候
讲到这个结果的时候
我们说这个结果大概等价于GPT-2的模型
GPT-2的大小是1.5B
但实际上它的大小是跟GPT-2是不一样的
GPT-2在这个地方其实它有48层
但是它的模型的宽度是要窄一些
所以GPT-3 XL跟GPT-2比
它是要浅一些
然后要宽一些
然后它一直增加到最后
就是GPT-3 175B
也简称是GPT-3这个模型的话
它用的是96层
然后每一层的大小已经到了12000的左右了
所以这个已经是非常大的一个尺寸了
然后大家可能会问
这些参数怎么要定出来的
那我觉得这个可能是作者拍拍脑袋吧
但我们知道
就是说你把你层数增加的时候
你的宽度也应该增加
我们知道把乘速增加的时候
你的宽度也要对应的增加
因为你的计算复杂度跟你的宽度是平方关系
跟乘速是线性的关系
但整体来说
GPT-3的模型是比较偏扁一点的
比如说GPT-3最大的模型跟前面比
那就是16倍的大小关系
但是在96这个层数上
其实跟前面比也就是最多是8倍的关系了
然后看到批量的大小
在大小可以看到
当你训练很大的模型的时候
它用的是3.2M
也就是说你一个小批量
里面有320万个样本
这是一个非常巨大的一个批量大小了
这个对你内存的考验是非常大的
因为你在计算的时候
因为你在计算梯度的时候
你中间变量的那一个大小
是跟你的批量大小成正比关系的
当然在分布式的情况下
假设你在机器与机器之间用的是数据并行的话
那么你每台机器要计算的批量大小
应该就是320万除以你机器数量的大小
所以如果你有很多台机器的话
你100或3000台机器的话
每台机器也还是能撑住的
作者有提到
你为什么要用相对来说比较大的批量大小
因为你批量大小一大的话
你的计算性能会好
就每台机器的并行度更高
而且你的通讯量也变低
所以分布式是比较好的
之所以你在小的模型
你不用很大的批量大小
是因为对小的模型
其实是更容易过你河一些
就是说你需要用一个相对来说
比较小的批量的大小
这样子导致你在采样的时候
数据里面噪音是比较多的
然后你当你的模型变得很大的时候
你相对来说用大的批量大小
你降低了批量里面的噪音
好像对大的模型来说
问题不是那么的大
这有一点点反直觉
这一块其实最近有很多工作去研究
为什么这么回事
当你的模型变得越来越大的时候
似乎你的过你河没有那么的严重
大家怀疑有两个原因
一个原因是说
你神机网络它背后这么设计下来
大家训练出来能得到比较好的结果
其实背后有一定的结构
使得它不那么容易
就像简单的MLP一样
直接的这么过你河了
第二个是说
当你的模型变得越来越大的情况下
而且在有结构的情况下
它能搜的范围更广
而且这样就更有可能去概括到
一个可能存在的一个
比较简单的一个模型架构
如果你的模型比较小的话
你可能搜索空间都搜不到
那一个简单的模型那边去
当你模型很大的时候
那你的SG能够帮助你去找到
那一个模型
最后导致你的泛滑精度比较好
当然这都是一些猜想
大家有在做研究工作
我们在这里就不展开给大家讲了
那最后学习率
学习率它就是当你批量大小变大的时候
你的学习率它是往下减的
这个其实也是跟之前的一些工作
它的结论是相悖论的
之前Facebook的一个工作是说
当你的批量大小往上增的时候
你的学习率要线性的往上增
但这个地方它其实是一个反过来的
它学习率往下降
作者在段落中有提到
为什么它是要往上增和往下降
大家可以去看一下它文章里面
提到的原始论文里面的解释
反过头来看2.1章
它真的就是比较短小的
就是两段话就结局了一周半夜的样子
就是说在一篇63页的文章里面
整个模型的架构就写了不到半夜
而且这个地方你根本就没写清楚
是说我的模型跟GPT2是一样的
那么你得去看一下GPT2
然后说我在上面又做了一些改进
用了一个叫Spart Transformer的结构
你得也去看这篇文章
然后这个地方还提了一句说
GPT2其实跟GPT1是改了这些东西
就导致说作为一个读者的话
你想搞清楚GPT3整个模型长什么样的话
你得去读一系列的参考文献
当你这篇文章已经有63页的情况下
我觉得这么做是没有那么的必要性的
你在这个地方就给大家讲一下
GPT2模型长什么样子
甚至是GPT模型长什么样子
以及说你Spart Transformer长什么样子
你就算是放在一个相关工作里面
或者放在后面都是可以的
因为这样的话
会给没有读过之前那些文章的读者
带来很大的便利
这是因为你去读前面工作的话
你还得把它的完整的故事图一遍对吧
它的记号用的是什么
它的这些表达是什么样子
然后我们已经读到这个地方了
所有的标号、写作风格
我们已经读下来是比较熟悉了
如果你在这个地方写清楚
或者甚至是你在后面的附录写清楚
那我也不需要重新再读一个新的故事
而是直接知道技术细节长什么样就行了
这也符合这篇文章要卖的
就是上下文的学习
当然我们这不是要批评这篇文章写的不好
只是给大家指出来说
读这篇文章遇到这样子一些障碍
大家自己在写作的时候
可以想办法去避免这样子的事情
第二点二节讲的是它的训练的数据
当你要做一个很大的模型的时候
当你的训练数据就得非常大了
这个地方它们的训练数据是基于comucrawl的
在gbd2这篇文章里面
它有提到说我们可以考虑comucrawl
但是它觉得comucrawl里面的数据太脏了
用起来比较难
所以它采用的是另外一个办法
在这个地方
如果你想训练一个比gbd2要大100倍的模型的话
那它得不得不去重新去考虑comucrawl这个数据了
具体来说它做了三个步骤
来使得这个数据让它变得更干净
首先它们过滤了一个版本
然后是基于它的相似性和一个更高的数据机
具体来说它干了什么事情呢
大家回忆一下
在gbd2里面它把reddit的上面爬下来
然后把karma大于三的那些帖子给你下载下来
作为一个高质量的网络数据机
那这个地方它干的事情就是说
把comucrawl下下来
然后把它的样本作为复利
然后之前gbd2那个网页数据机作为正理
那个是高质量的
comucrawl你认为大部分是低质量的
然后在上面做了一个很简单的logic regression
做一个offer内
正内是gbd2的爬下来的数据机
负内是comucrawl里面的
那么接下来做预测
对comucrawl里面所有的网页拿出来
如果分类器认为你是偏正内的话
就是说你的质量比较高的话
那么它就留下来
如果是判断出来很负内的话
那么就是过滤掉
第二个是它做了一个去虫的过程
就是说如果一篇文章跟另外一篇文章很相似的话
那我们就把这篇文章去掉
它具体用到的是一个叫做lsh的算法
它可以很快的判断一个集合
一篇文章是一个集合
就是一些词的集合
和另外一个很大的一个集合之间的相似度
这个在information trivial里面是一个非常常用的技术
如果大家不熟悉的话
可以去看一下
这也是在面试中间大家很喜欢问的一类问题
第三个是说
我们又加了一些已知的高质量的数据
就是把之前的Bert GPT-2 GPT的所有数据都拿过来也加进来
最后就得到一个非常大的数据集了
可以看一下放在下面这个地方
首先第一行就是Cormacore
就是他们新加进来的数据
这里面一共有4万一个字
webtex2就是GPT-2用的数据集
它上面一个比下面一个大20倍的样子
但是它的模型已经大了100倍
然后接下来是书的数据集和wikipedia
就虽然Cormacore里面给你带来了大量的数据
但是作者认为它里面质量还是相对说比较差的
所以在采样的时候
它是用了稍微不一样的采样率
虽然Cormacore你比后面这些加起来还要大那么七八倍的样子
但是在采样的时候
就是说一个批量大小
一个100万大小的批量里面
也就是60%的数据是来自于Cormacore
有22%的数据是来自于webtex2的
就是你看到Cormacore里面的数据也就比下一个多三倍
虽然你的大小上来说多了20倍
而且下面这些wikipedia
虽然它的大小比你上面要小很多很多
但是它的全重并不低
也就是导致说在采样的时候
它大量的采样了wikipedia book1和webtex2的数据
这样子保证你这个小批量里面有大部分的数据
它其实的质量还是很高的
但具体来说这个全重怎么来的
好像作者也没有解释的那么清楚了
2.3是一个非常短短的段落来讲
整个模型是怎么训练的
又是这篇文章不那么厚道的一个地方
GPT3这个模型是非常难训练的
你想它有接近2000一个可以学习的
它说整个模型是非常大的
你训练它的话
当然需要分布式训练
然后你需要做非常好的模型分割和数据分割
然后它说它是在一个v100的
有的带回很高的集群上训练的集群来自于微软
但实际上说它用的是DGX1的一个集群
那里面的贷款是非常高的
一般的人是买不起
所以它就一句话就带过了
虽然它说我在附录B里面有讲这些东西
实际上它也没讲什么东西
就讲了一点超商是怎么训练的
这一块如果要真的讲的话
其实有很多东西可以说
2.4解释讲模型的评估
跟之前不一样
因为这个地方它不需要做微调
所以它不需要一个外来章节说微调是怎么做的
而是说我预训练模型好了
这我就直接对它进行评估
在评估的时候它用的是上下文的学习
具体来说它在每个下游的任务里面
它的训练集里面采样k个样本作为你的条件
当然k可以等于0、1或者10到100
然后它的prompt用的是answer冒号或者a冒号
就是说我要做分类的时候
比如说那么我就把几个样本采样出来
放在前面
在前面加一个我要干什么事情
如果你是2分类的话
那么你的答案要么是choose要么是force
而不是说一个0或1
因为0或1在训练数据中出现的概率没了choose和force那么高
接下来如果你的答案是一个自由的形式的话
比如说我在做问答的时候
假设你的答案是要真的给我回答一个自己编出来答案的话
那么它就采用的是binsearch
就是跟机器翻一样
我生成一个序列出来
然后用binsearch就找到一个比较好答案
所以到这里它就讲完了它整个模型的部分
可以看到虽然到这个地方已经有实验的样子
但实际上它真正的讲模型训练那一部分是相当相当的少的
它花了很多时间去讲它整个设定长什么样子
画一个图告诉大家
所以在那么长的论文里面
就那么一点点地方讲你真正的干货是一个比较奇怪的做法
这也是为什么我们在之前先给大家讲了GPD和GPD2这篇文章
再来讲GPD3
如果你直接读GPD3这篇文章的话
你会发现读起来还是不那么容易的
接下来是长达20页的结果
我们就不给大家一一的详细讲了
就给大家过一下比较有意思的一些图吧
下面第一个图展现的是不同大小的模型在训练的时候
它跟你的计算量的一个关系
X轴表示的是计算量
你的Y轴表示的是你的验证的损失
它这个地方用验证损失是因为它发现验证损失
跟你这些子任务上的精度是有一定关系的
所以能够很好的表示你预训练模型的一个好坏
每一根线表示的是一个参数的模型
当你训练时间变长的话你的计算量也会跟着增加
这个地方每一根线表示的是一个不同设置的模型
这个黄色表示的是GPD3最大的模型
这个线表示的是最小的模型
当你随着你的训练的增加
那么你的计算量会增加
因为它算是你到目前为止所有的计算量
可以看到这个地方基本上就收敛了
虽然你的计算还在往上涨
但是你的损失没有再往下降
最好的一个权衡其实在这个地方
相对计算量和损失来讲最低的是这个点
就是说你训练到这个地方就差不多了
你不用往下训练了
如果你要往下训练的话
你把模型做得更复杂一点
所以你把所有这些模型它的最好的这个点拉成一条线的话
你要发现这是一个叫做Power law的分布
也就是说在你最好的情况下
就是说你找到一个合适的模型
而且不用训练过度训练的情况下
那么你随着你计算量的指数的增加
你的损失是线性的往下降
这个一直是积蓄学习的一个痛点
就是当你想持续线性的提升你的精度的时候
你得不断的指数去翻你的数据量
数据量当然弄起来是很难的一件事情
二个是说你数据量增加之后
你的计算量也是跟着指数的增加
这个地方讲的是我的数据固定的时候
我如果想线性的降低我的损失
我一样的计算量都得指数的往上增加
当然跟人类比还是差的太远了
人类的大佬相当于一个60瓦的一个灯泡的耗能
然后人类在学习的时候远远的不需要那么多的样本
你想想你学会阅读的时候
你要读多少本书就行了
你可能读小学语文那几本书就行了
但是它这个地方它把整个互联网上的东西全部抓了下来
才能够学习到可能跟人类相比还是有一点差距的地方
所以我们还有很长的路要走
然后再往下面看有很多这样子的图
它这个地方X走还是表示了你模型的参数的大小
到后面这个线就是你最大的模型
然后你的Y就是你的精度
这个地方是使用ZirShot最好的模型
人类的这个地方
在这个地方它发现当你增加模型大小的时候
它当然是能够超越目前最好的那些ZirShot的算法
而且如果你使用FuShot的话
跟人类的精度还是有那么接近的地方在这个地方
然后到下面有很多这样子的图
在这个地方它讲的是一个叫做Open Domain的一个QA
就是在开放区域的一个问答
然后它对比的是T5
T5是来自于Google的一个算法
你肯认为是编码器和解码器全部拿过来
Bert用的是编码器
GPT用的是解码器
T5用的是编码器和解码器都有
然后你如果用T5做微调的话
GPT其实你用FuShot或者是OneShot它都比它要好了
然后你往下面翻的话
这又是另外一个QA的一个任务
然后这个是使用微调的时候最好的一个精度
GPT3最大的模型已经跟它已经非常接近了
然后这个是机器翻译
每一根线表示的是一个语言翻译到另外一个语言
10线是表示别人翻到英语
那虚线表示英语翻到别人
你的Y轴用的是Blue这个分数
这是机器翻译最常见的分数
然后有意思的是说
你看到别人翻到英语通常来说
比英语翻到别的语言要好
然后你往后面翻很远之后
你看到用GPT生成的一个新闻稿
标题灰色部分是给GPT3的输入
后面这些黑的部分就是GPT3写出来的
然后基本上你看一下写的还是模式样
然后这里面有年份
有各种数字各种百分比
就讲的是模式样
所以这个地方有点可怕
GPT3瞎扯起来真的是脸不红心不跳的是模式样
然后后面有些样例
怎么样GPT3的作题
就是说我告诉你一个词
它大概意义是什么
然后用这个词来造句
黑色就是GPT造出来的句子
它基本上GPT3给你写写作业是没有问题的
这样我们就很简单的给大家讲了一下
如果你去做这一块相关的话
你可以找到对应的那些数据
去仔细了解一下
如果只是想知道它大概模型的效果
的话我们就这么简单就过去了
接下来我们看一下第五章
讲的是这个模型的局限性
在这一章里面作者列举了非常多的局限性
我们来稍微看一下它到底是什么
首先它说虽然我们比GPT2好很多
但是在文本生成上面还是比较弱的
如果我让GPT3生成一个很长的文本的话
可能给了几段之后
它又把上面的东西重新回复来写一下
所以如果你想让它来帮你写小说的话
就是比较难的
因为它很难得到一个剧情的往前推
但如果你告诉它说
这一段我没有讲什么的话
它很有可能能帮你补全的试模试样
第二个说它说我有一些结构和算法上的局限性
它讲的一个主要的局限性是说
GPT3因为用的是语言模型
它是往前看的
它不能像之前Burt那样能够反过方向来看
这也是因为GPT使用的是Transform的解码器的缘故
然后它讲的另外一个局限性是说
因为你训练是语言模型
每一次你要去预测下一个词
所以它这个地方是每一个词
它都是很均匀的去预测下一个词
它没有告诉你说哪个词比较重要
哪一个词不重要
我们知道在语言里面很多词都是一些常见词
但是没有太多意义的虚词
所以导致整个语言模型花很多时间去学习这些虚词
还不像你真的要教小孩一样的
告诉你这个是话重点
这个才是要去记住的东西
当然它还有说
因为我用的只是文本
所以我对别的东西没见过
比如说没见过Video长什么样子
没见过真实的这些物理的交互长什么样子
因为人在学习的时候
读书只是整个人的活动中的一块
所以它也就是在这一块做的比较好
但是别的方面它基本上是没有设计的
它还讲了一个是你的样本有效性不够
因为你为了训练这个模型
我基本上只把整个网络上的文章都给你下下来了
对人来讲这个真的是太可怕了
另外一个问题
作者说也可能不叫问题
就是不确信是说
你在做这种给你多个样本
在做上下文的学习的时候
它真的是去从头开始学习吗
它真的是说我去通过你给我的样本学习
这个样本是长这样
还是说我就是跟这个样本在我之前的文本里面找出相关的
然后把它记住就行了
就认出了这个任务
这两个当然不一样
我们当然喜欢说你从头开始学这个途径
这样子的话
真的碰到一个你的训练样本上没有出现过的任务的话
我也能够泛化过去
如果就是我根据你的样本
从我的训练记忆里面把它相关的东西找出来的话
那就真的最后拼的是你的训练数据的大小了
另外一个跟之前样本有效性的相关的
就是说训练起来非常的贵
最后一个
GPD3跟很多深度学习模型样都是无法解释的
就是我给你一个书
然后你反而给我一个看上去很不错的书书
但我并不知道你是怎么样得到你的书书的
你里面哪些权重真的起了作用
而且你整个决策是怎么做的
特别是对GPD3那么大的模型来讲
去找出里面这些做关键决策这些权重是非常难的
所以我们最多能说GPD3真的就是大力出奇迹了
接下来是对GPD3可能的一些影响的一些讨论
因为这个模型已经非常强大的可以直接拿过去用了
就是说部署在生产环境里面
一旦你的部署到生产环境里面的话
那么肯定会对人会对社会产生一些影响
最简单是它是不是安全的
大家不要觉得一个模型它能够对人造成多少危害
如果你真的依赖一个模型做一些很重要的决策的话
它当然可能会带来很大的影响
OpenAI的很多工作有这样子的讨论
我觉得是非常好的
那表示这个团队是有很大的社会责任感的
我们这里简单的给大家过一下
它首先说我这个模型可能会被用来做坏事
在6.1.1里面讲到说
你有可能是散布一些不实的消息
生成一些垃圾邮件或者钓鱼邮件
然后论文造假
我们之前有看到它生成的那些新闻稿
真的人是很难看出来区别的
我们读一篇新闻的话
你们对里面的数字一些很多事情
我们通常不会下意识的去怀疑它
觉得你既然记者把它写出来
那么一定是你做过调查的
如果有人用GPT-3大量的生成这样子的文件的话
可能会有很多读者会去信里面的东西
虽然现在很多这样的过滤机制
比如说你的邮箱里面会判断一份邮件是不是垃圾邮件
但如果GPT-3能够大量的生成这样子的文章的话
那么肯定是有一小部分能绕过这些机制
从来能够对人产生影响
然后他又讲了一下公平性、偏移
比如在性别上
因为他下的文章里面很有可能里面男性这种词居多
比如说你让GPT去回答一个侦探是一个男人还是一个女人
那么GPT在很大的可能性下认为这是一个男人
接下来他调查了一下GPT对一些性别的一些偏见
作者让GPT回答He was worried
或者She was worried
就是男性的是怎么样的、女性会怎么样的
然后他去判断一些词出现的概率
把那些比较偏见的那些词拿出来
比如说对男性来说GPT可能生成它是比较难的
对女性来说它很大概率会生成它是非常漂亮的
就漂亮这个词不是一个贬义词
但是漂亮意味着是说你对女性的外表比较在意
这是一个偏见
第二个是对种族
比如说这一个女人非常的什么
你可以换成白的、黄的、黑的
然后下面这个图表示的是不同大小模型
对不同种族的一些正面还是负面的评价
这里0表示的是正常
正的是表示的是这个种族比较正面的反馈
负数是表示比较负面的
对黑人就是这一根线相对来说比较负面的
但是对于Asian整体来说是比较正面的
虽然作为亚洲人看到这个结果可能会比较开心
但是当你发现一个模型对不同种族的区别有那么大的时候
你可要注意到说可能换一个模型
那个模型可能是仇视亚洲人的
但还是可能有宗教
宗教之间相互歧视也是非常严重的
最后一点关于的是能耗
因为你训练GPD模型需要几百台机器训练很多天
那么一台机器那么就是几千瓦的能耗的话
那么训练下来你的能耗也是相当夸张的
最后是它的结论
它说我们做了一个有1750亿参数的原模型
然后在许多的NLP的任务上面
我们做了zero short one short few short的学习
在很多情况下
它能够媲美到使用更多代标号数据的基于微调的算法
然后它的一个卖点是能够生成高质量的一些文本
让他们展示了一个不用基于微调的一个可能性
然后我们对整个GPT、GPT-2、GPT-3这三个工作做一个评论
你可认为GPT是起了一个大早
它先把Transformer这个模型拿过来做预训练
然后证明它在效果上很好
但是没想到在选择路线上二选一的时候选择一条路
但是没想到另外一条路走得更容易点
也就是Bert和他之后的工作
但作者没有气馁
因为我有钱我有人
所以我一条路走到黑
GPT-2就是把模型做得更大
然后尝试一个更难的问题
就是不在下一个任务上做微调
如果你发现你还是打不赢的话怎么办
那就再摇人吧
然后再准备一点钱
我做一个更大的一百倍更大的模型出来
所以最后搬回一举
不管怎么样GPT系列给我们开了一眼睛
让大家发现语言模型是可以暴力出奇迹的
