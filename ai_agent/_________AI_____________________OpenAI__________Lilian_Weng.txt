大家好
这里是最佳拍档
我是大飞
最近几个月
随着大语言模型的持续火爆
利用大模型来构建AI智能体的研究
也陆续进入了人们的视野
AI智能体这个概念
也逐渐的流行开来
先是斯坦福大学
谷歌的研究者们
成功的构建了一个薰衣小镇
小镇上的居民不再是人
而是25个AI的智能体
他们的行为比人类角色扮演
更加真实
甚至还举办了一场情人节的派对
随后商汤清华等机构
提出了能够自主学习
解决任务的通才AI智能体
GITM
在我的世界中
比以往所有的智能体
都更有优秀的表现
同一时间
英伟达开源的Voyager
也给AI圈带来了不小的震撼
作为一个大模型驱动
可以终身学习的游戏智能体
Voyager在我的世界中
玩出了很高的水平
这些AI智能体的先后涌现
甚至让人认为
是未来通用人工智能AGI的雏形
很多AI领域的大佬和科技巨头
对AI智能体的发展
都产生了极大的兴趣
并寄予了后望
今年年初回归OpenAI的安德烈卡帕西
在OpenAI的黑客马拉松活动上就透露
每当有新的AI智能体论文出现的时候
OpenAI内部就会感到非常的有兴趣
并且认真地进行讨论
那么我们不禁要问
到底什么是AI智能体
它有哪些部分组成
它的神奇之处
又具体表现在哪些方面呢
近日OpenAI安全系统的负责人
Lillian Weng就写了一篇
关于AI智能体的博客
首先简单介绍一下作者
Lillian Weng是2018年加入的OpenAI
在GBT-4项目中
主要参与运训链
强化学习和对齐
模型安全等方面的工作
在他的这篇博客文章中
他就认为AI智能体的核心驱动力
是大语言模型
而规划、planning、记忆、memory
和工具使用、to use
是实现他的三个关键组件
Lillian Weng对每个组件
都展开了详细的剖析
并且提供了一些案例的研究
比如说科学发现智能体
生成式智能体模拟
和概念验证的施力
对于AI智能体未来
将面临哪些挑战呢
他也给出了自己的观点
我对文章的内容做了一些提炼
在这里跟大家分享一下
有兴趣的同学
可以去详细阅读一下原文
首先Lillian介绍了一下
智能体系统的概念
在大语言模型
附能的自主智能体系统中
大语言模型充当了智能体的大脑
它有三个关键的组件
首先是规划
规划又分为两个部分
一个是子目标和分解
智能体可以将大型的任务
分解为更小可管理的子目标
从而高效的处理复杂的任务
第二个是反思和完善
智能体可以对过去的行为
展开自我批评和自我反思
从错误中吸取教训
并针对未来的步骤进行完善
提高最终结果的质量
其次的组件是记忆
分为短期记忆和长期记忆
所有的上下文学习
都是利用了模型的短期记忆来学习
而通常利用外部向量存储
和快速减缩的能力
为智能体提供长时间
保留和回忆记忆的能力
最后是工具的使用
智能体可以学会调用外部的API
来获取模型权重中
缺失的额外信息
这些信息通常在预信链之后
很难改变
包括当前的信息
代码执行能力
以及对专有信息员的访问等等
随后作者分别详细讲解了
这三个关键的组件
首先规划
我们知道一项复杂的任务
通常会涉及到许多的步骤
智能体必须了解任务是什么
并提前进行规划
那么这就会涉及到任务的分解
以及相关的技术
首先是思维链COT
它已经成为了增强复杂任务上
模型性能的标准提示技术
在实现过程中
模型被指示一步一步的思考
从而利用更多的测试时间计算
将困难任务分解为
更小更简单的步骤
COT可以将大型的任务
转化为多个可管理的小任务
并解释清楚模型的思维过程
其次是思维术TOT
它通过在每一步探索
多种推理可能性
来扩展了COT
首先它会将问题分解为
多个思考步骤
并且在每个步骤中生成多个思考
创建一种竖形的结构
搜索过程可以是广度优先搜索BFS
或者是深度优先搜索DFS
其中每个状态由分类器
或者是多数的投票来进行评估
具体来说就是任务分解过程中
可以通过以下三种方式来完成
第一种方式是
基于大语言模型的简单提示
比如XYZ的步骤是什么
实现XYZ的子目标是什么
第二种是使用特定于任务的指示
比如说写一个故事的大纲
或者是第三种人工熟
另一种截然不同的方法
是使用LLM+P
它靠外部的经典规划器
来进行长期的规划
这个方法会利用规划领域定义语言
PDDL作为描述规划问题的中间接口
在这个过程中
大语言模型会首先将问题
转化为Problem PDDL
然后请求经典的规划器
基于现有的Domain PDDL
生成PDDL规划
最后再将PDTL规划转换回自然的语言
本质上规划步骤
被外包给了外部的工具
并且假设可以使用特定领域的PDDL
和合适的规划器
这在某些机器人的设置中很常见
但是在许多其他领域并不常见
在规划过程中
自我反思Self Reflection
它允许自主智能体
通过完善以往的行动决策
和纠正以往的错误来迭代改进
依然会在出现试做的现实世界任务中
发挥至关重要的作用
React方法能够通过将动作空间
扩展为一个任务特定的
离散动作和语言空间的组合
从而将推理和动作
集成在大语言模型中
离散动作使得大语言模型
能够与环境交互
例如使用维基百科的搜索API
而语言空间促使大语言模型
以自然语言的方式来生成推理轨迹
Reflection框架则为智能体
配备了动态记忆和自我反思的能力
提高了推理的技能
它有一个标准的强化学习设置
其中奖励模型提供了简单的二元奖励
而动作空间则遵循了React中的设置
Chain of High Sight COH
这种方式鼓励模型通过显示的
呈现一系列过去的输出
来改进它自己的输出
其中每个输出都带有了反馈的注视
为了避免过拧核
COH添加了正则画像
来最大化的预训练数据集的对数自然
同时为了避免捷径和复制
研究者们在训练过程中
随机屏蔽了0%~5%的过去的token
COH的思路是呈现上下文中
连续改进输出的历史
并且训练模型产生更好的输出
算法蒸留AD
它是将相同的思路
用到了强化学习任务中的跨情节轨迹
尽管AD算法仅仅使用了离线的强化学习
但是它的性能接近于L评方
在线强化学习算法
并且学习速度比专家蒸留
和原策略算法要快得多
其次是记忆组件
记忆分为三种类型
第一种是感知记忆
第二种是短期记忆STM
或者称为工作记忆
第三种就是长期记忆LTM
其中感知记忆是记忆的早期阶段
它能够在原始次级结束后
保持对感官信息
比如说视觉听觉等的印象
感知记忆通常只能持续几秒钟
它的子类包括图像记忆
回声记忆和触摸记忆
而短期记忆STM或者称为工作记忆
存储着我们目前所知道的信息
以及执行复杂认知任务
比如学习和推理所需要的信息
一般来讲短期记忆可以持续20~30秒
而长期记忆可以将信息储存很长的时间
从几天到几十年不等
它的存储容量基本上是无限的
长期记忆有两种子类别
分别是显示陈述性记忆
和隐世的程序性记忆
前者是对事实和事件的记忆
指的是那些可以有意识的回忆起来的记忆
包括记忆事件和经过的情景记忆
以及记忆事实和概念的语意记忆
后者的记忆是无意识的
涉及到自主执行的技能和习惯
比如说骑自行车或者在键盘上打字
参考人类记忆的分类
我们可以得到几种映射关系
感知记忆可以作为原始输入的学习嵌入表示
短期记忆作为上下文学习
由于受到Transformer有限上下文穿口长度的限制
短期记忆是短暂而且有限的
长期记忆作为外部的向量存储
智能体可以查询快速检索从而进行访问
外部记忆可以缓解注意力的一些限制
为了更好的处理外部记忆
一个常见的做法是将信息的嵌入表示
保存到一个向量存储数据库中
这个数据库可以支持快速的最大内机搜索M.I.P.S
为了优化解锁的速度
研究者经常使用的方法是近似最近临AN算法
在加速M.I.P.S中经常会用到的AN算法
包括局部敏感哈希(LSH)
近似最近临ANNOI
分层可导小世界(HNSW)
Facebook AI团队开源的酷Face
以及可扩展最近临Scan算法
更多的M.I.P.S算法和性能的比较
可以在annbenchmarks.com中查看
第三个关键组件是使用工具
使用工具是人类的一个显著特点
我们创造 修改和利用外部的物体
来探知和认知现实世界
类似的 给大语言模型配备外部的工具
可以大幅的扩展模型的能力
MRKL是一种用于自主智能体的
神经符号架构
命名来源于模块化推理
modular reasoning
知识knowledge和语言language
这三者的简称
每个MRKL系统都包含一些专家模块
通用的大语言模型作为一个路由器
负责将查询路由到最合适的专家模块
这些模块可以是神经网络的
例如深度学习模型
也可以是符号的
例如数学计算器
货币转换器
天气的API
MRKL的研究团队
使用数学计算进行实验
实验结果证实
当外部符号工具能够可靠的工作时
知道何时和如何使用这些工具
是至关重要的
而这个是由大语言模型的能力决定的
ChadGBT的插件和OpenEye的API函数调用
就是大语言模型使用工具
在增强能力的最好实力
工具API的集合
可以是由其他开发者提供的插件
或者是自定义的函数调用
HuginGBT则是一个利用ChadGBT
作为任务规划器的框架
根据模型的描述
来选择HuginFace平台中可以使用的模型
并且根据执行的结果
归纳总结处响应
HuginGBT由四个阶段组成
第一个任务规划阶段
大语言模型作为大脑
将用户请求解析为多个任务
每个任务有四个关联的属性
分别是任务类型
任务ID
依赖项和参数
研究团队使用了少量的例子
来指导大语言模型
进行任务解析和规划
第二个模型选择阶段
大语言模型会从一个模型列表中
选择模型
将任务分配给专家模型
由于上下文长度有限
就需要进行基于任务类型的过滤
第三个就是任务的执行阶段
专家模型执行具体的任务
并且记录任务结果
第四个是响应的生成阶段
大语言模型接收执行的结果
并向用户提供总体的结果
HuginGBT在实际使用中
还需要解决几个挑战
第一个就是需要提高效率
因为大语言模型的推理
以及与其他模型的交互
都会减慢进程
第二它依赖于一个长的上下文窗口
来沟通复杂的任务内容
第三个提高大语言模型输出
和外部模型服务的稳定性
接下来Lillian还介绍了一个
评估工具增强型大语言模型
性能的基准
API bank
它包含了53个常用的API工具
一个完整的工具增强型
大语言模型工作流
以及涉及568个API调用的
264个已注释的对话
API bank基准中
可以选择的API相当的多样化
包括搜索引擎
计算器
日历查询
智能家居控制
日程管理等等
大语言模型首先可以通过API
搜索引擎
找到合适的API进行调用
然后使用相关的文档来调用API
在API bank的工作流中
大语言模型需要做出一些决定
包括是否需要调用API
确定要调用的正确的API
以及基于API结果的响应
这个基准在三个层次上
评估了智能体的工具使用能力
包括调用API的能力
检索API的能力
以及检索和调用之外
规划API的能力
考虑到不明确的用户需求
模型可能会需要进行多次的API
调用来解决实际的问题
随后Lillian介绍了一个案例
一个用来进行科学发现的
智能体camcraw
它是一个由大型语言模型
设计的化学智能体
能够完成有机合成
药物发现和材料设计方面的任务
通过整合17种专家设计的工具
camcraw提高了大语言模型
在化学方面的性能
并衍生出了新的能力
有趣的是
尽管基于大语言模型的评估结果
得出的结论是GPT-4
和camcraw的性能几乎相当
但是经过专家人工的评估表明
camcraw在很大程度上优于GPT-4
Lillian还提到了生成式智能体的概念
它能够将大语言模型
与记忆 规划和反射机制相结合
使得智能体能够根据过去的经验
做出反应
并且与其他的智能体进行交互
有关智能体
大家应该最熟悉的例子
就是AutoGPT了
有了它人类无需插手
AutoGPT就能够自主完成任务
具体来说
AutoGPT就相当于给基于GPT的模型
有了一个内存和身体
有了它你就可以把一项任务
交给AI的智能体
让它自主的提出一个计划
然后去执行这个计划
此外它还具有互联网访问
长期和短期的内存管理
用于文本生成的GPT-4实例
以及使用GPT 3.5进行文件存储
和生成摘要等等功能
此外作者还列举了GPT engine这个项目
和代码生成类的工具差不多
能够根据提示生成一整个代码库
最后作者也提出了基于大语言模型
构建智能体的一些限制
包括有限的上下文长度
长期规划和任务分解还要面临的挑战
以及自然语言接口的可靠性
好了 以上就是Lily Wong
对AI智能体的介绍和分析
完整的内容
大家可以去自己阅读一下原文
里边还有一些数学公式和伪代码
可以供大家参考
感谢大家观看本期的视频
我们下期再见
