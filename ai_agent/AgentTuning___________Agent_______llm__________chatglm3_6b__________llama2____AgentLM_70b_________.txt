前两天的话清华发布了XRM3-6B
我们都知道它里面有个核心的能力
就是对于Agent这块的处理的话
具有原生的Agent处理能力
那么它这个能力来自于哪呢
也就是我们今天要介绍的这个Agent Tanning
它是清华发布的首歌
利用多个Agent任务交互轨迹
对大模型进行指令微调的一种新的方法
这种方法以前我们如果知道构建一个Agent的话
我们要了解大元模型的底层
它是不是本身具备这个能力
那么如果不具备的话
那么这个时候我们就没办法去直接用它
还是需要构建一些外部的SOP
来补充它的对任务执行能力
但对于我们真正在事务里面
这样的话会浪费很多的这种开发资源
但如果说我们日常在工作场景里面
可能这种实际在应用的时候
会碰到要构建很多Agent的这种场景
一个公司的业务里面可能涉及各种各样的Agent
那么这个时候怎么办呢
我们就可以把大量的Agent来做一些个微调和训练
因为你这个时候就会发现微调
可能它的成本要远低于个性化构建Agent的成本
OK 那么我们就可以采用Agent Tanning这种方法来做
它的话是我们以前构建Agent都是用外部的SOP来弥补
Agent这个大模型本身在多任务处理方面的不足
那么今天的话是我们是希望让大模型本身具备这种任务的处理能力
那么的话它是基于Lama2微调出的一个Agent LIM70B的这么一个model
它本身具有很好的一个就是面向任务的这种泛化能力
然后另外的话在通用语言的处理方面的话
也没有丧失太多的能力
OK 我们下面来看一下这个项目
然后这个项目的话大概它的原理结构图就这个样子
就这里的话有Head in task
然后还有这个Head out task
Head in task什么意思呢
就是说我们用来训练的任务的一个数据集
这里面包含几个类型
它用了六种类型来训练
一种是操作系统的包括数据库的训练集
然后还有这个Web Navigation和Knowledge知识图谱
就是网页的一些个任务
还有这个底下还有这个购物的一些个数据
以及家庭日常的这种日常任务
比如说你让你说
帮我把这两个垃圾扔到垃圾桶这些个任务
日常的一些任务
那么的话像这些的话就是说基于这些数据
这些特定任务的数据
这个任务它是由三个部分组成的
每一条的这个数据集都有三个数据组成
哪三个呢?第一个的话是具体这个任务的一个
应该说它的一个任务的一个大概一个描述
然后第二个任务的一个目标
然后第二个的话是由任务的执行轨迹
就是说这个任务它怎么思考来执行这个任务的
比如说你在让GDP4你别问它一个问题
然后你底下再描述一个就是思考的时候
step by step
那么它给你输出的时候
它就会按照一步、二步、三步、四步、五步
怎么来思考的就会给你输出出来
那么这里的这个意思就是说
这就是它执行的轨迹其实就是中间的step by step这个过程
然后还有一个的话就是说对于轨迹的这么一个交互
大概有这三个部分组成
然后这三个部分的话相当经过这个agent instructor
构成了这个agent instructor
构成这个东西之后
那么的话下一步就是说进入训练用了LAMA
它用了LAMA2的一个底座module来进行训练的
然后训练然后同时用了两个数据集
一个是这个特定的这个任务数据集
同时还用了一些个通用的一些个指令微调的数据集
那么两个进去之后调出了它一些能力
这个调出来之后它会发现除了原先本身数据集
像这种操作系统、任务、还有数据库任务
这六个就是已经训练这个任务的表现还不错之外
它还获得了一些新的能力
比如说像这个数字卡游戏的这种
玩游戏的能力、任务规划能力
还有这个日常的这个电脑任务的这种能力
还有科学的这个经验实验的能力
就是web网页交互能力、VK的这种问答能力
这相当增加了一些新的能力
这就是它是泛化能力
大概就这么整个这么一个逻辑
然后它的话是首个利用了
多个agent任务交互轨迹对大模型进行指令误调的方法
这里的话这个用通俗话来解释什么样子呢
就是说我们都知道咱们在用AutoGPC的时候
你给它一个任务对吧
它会中间会有很多部组
包括我们以前讲的Xagent这些部组
就相当于这个数据集就是说
你把那中间的部组问题和中间的这个交互轨迹
都输出给这个大模型去做训练然后扔给它
然后让它就有点像我们以前像这个提示词里面有个说法叫
就基于COT思维数的方式去进行FailShot
就给它一些示例
比如说你问一个GPC4的问题的时候
你可以给它几个示例
然后示例里面可以用这种
除了问题之外再加入一些个思考的过程
然后最后再输入答案
那么它给你输出的时候也会按照这种方式
这个微调其实就类似于它用的数据集就是那种数据集
OK 然后它的数据集和这个模型都已经开源了
如果有兴趣可以去研究它的数据集
比如说我们可以看一眼 看一眼它的数据的样子
然后的话就是说我们可以看它的表现
Heading task指的是它在这个已经训练的数据上的这种表现
就已经比如它训练过这种操作系统指令能力
还有这个数据库的这种任务能力
那么它在这方面的表现我们可以看到
它明显是高于这个LAMA的
这个JBG 3.5和这个LAMA它明显高的
像JBG 3.5也就这个水平 它是明显高于这些的
那么的话它在这个没有训练
Head out的意思就是没有训练过的数据集就是泛化能力
在泛化的这种任务上的话
它的表现也是远高于其他的model的
像LAMA从7B 13B到70B
再到JBG 3.5它也是远高的
同等参数规模下它是远远高于他们的
那么的话我们可以看到它在70B方面的表现
基本上跟JBG 3.5是持平的
那么这个表现就非常不错了
然后这边也有基于Agent Buncher的一个评分
我们可以看到它的这个表现也是非常好的
就是在这个就是Agent这方面
我们可以看到JBG 4它是这个4.41分
然后3的话是2.25分 对吧
然后这个等等这些其他的一些model等等一个表现
我们可以看到这个表现的一个分数
然后我们可以看一下刚才说的数据级
它数据级的话因为是任务
我们可以看到它的任务的描述什么样子呢
你比如说拿这个来说
比如它是来自于人loss然后value
你是一个有用的扮演一个人
然后他要玩一个Linux的一个操作系统的一个什么角色
要扮演Linux操作系统的一个角色
目标是玩 目标是补全这个操作系统
有我或者说回答问题的这个要做补全
然后你要怎么怎么
然后底下有一些个事例
如果你认为你应该执行什么办事命令
然后他任务开始执行
然后你应该输出这个ESI
就是说这个地方其实属于操作系统的一个指令
相当于操作系统的一个sync by sync的一个
这么一个数据级的一个指令
就是说这是一个事例
当然底下还有很多它不是有好多类别吗
有不同的类别 有wubuntu的
然后有不同的我们可以看到
就这个它搞了好多数据级 有不同的数据级
这有wubuntu的
然后这里的话就说你有db的
有这个日常生活里面比如ILF Word的这种
比如说你是人 这是交互
这就相当于有这么数据级吧
反正它数据级里面包含几个要素
就有几个要素
我们可以看到它的这个数据级的话有些特点
第一个的话是采用了React这种思维链的思考方式
React 我不知道大家知道React什么意思吗
React的话它是一种
就是说基于COT的一种数据级的一种
你可以理解我数据级的一种就是说这种构造方式吧
我其实一般对它这么理解
它其实用了一种特定的方法
你比如说它的这种数据级是什么呢
数据级是比如说React Racing加Act
就是它需要把推理过程和执行过程都表示出来
都表示出来这种样子就是一个React这种方式
就采用了这种训练方式
那么比如说你像咱们一般的话
就是说用XGPT的时候你问一个问题
立马给你答案 对吧
那种就不是React这种方式
React这种方式就是说你问他一个问题
那么他首先会做一个思考sort
思考完之后然后再有执行action
然后再有观察
然后完之后再有sort i
然后再有action2
然后再有观察 i
然后再有3 再有4
然后直到最后完成action4 照完成
它这么一个过程
所以它数据级的它采用的这种方式
用了思维链的这种数据级的数据级的构造方式
然后第二个的话多样性
多样性它涵盖了很多现实世界的场景
场景就刚才上面说的那几个场景
这六个场景
就说它用了这六个场景
然后再往下的话精准性
因为它的话就是说确保了
因为它每条数据质量的话
它就用Gb4做过一个对齐的
然后同时人工也做了一些教验
然后泛化方面的话也是不错的
然后它的数据已经开放出来了
如果说你要构造你特定场景的这种agent能力的话
你就可以在它的基础上再增加一些特定任务的这种
数据级
然后用它这个方法来
就是增强这个模型的agent的任务处理能力
这是可以的
然后我们可以看这个它就是通过这个
用了这种agent timing的方式训练出了这个agent LIM
它是基于lama2 chat这个module训练的
然后基于agentinstructor和shale-gpt这两个数据级训练
shale-gpt这个数据级的话
它是一个就是混合数据级上进行训练的
然后的话就是说这个是通用的
这个后面这个通用数据级
前面这个是agent特定数据级
然后系统提示词这个样子
然后它给你说的非常清楚
然后运行的时候就用底下这个命令来运行
我觉得这个项目相当跟我们提供了一种新的思路
它论文里面也写
它这个论文的话也写得非常不错
我大概看了一眼
就是说比这块架构我们刚才聊过了
然后再到底下这里
它用了这个数据
我们可以看到这个数据的一个情况
用了1866个这么一个高任务的
就相当于1866个这么一个任务的这么一个数据级
就1000多个
相当于这1000多个这个数据级都是经过
比如说有家庭任务的 有网上购物的
比如针对一个购物场景
可能这个购物场景一步二步三步四步五步
它怎么执行的
这个里面都是它的数据级里面都有对应的一个说明
然后这个后面有对应的一个就是训练了几轮
这个轮次的一个比例
然后后面还有retail的一个比例 OK
然后我们再看一下 下面还有一个地方我们可以看一下
那它在还有的 我们看它在这个
就是说这个已经训练的数据级上的一个表现
和这个犯化任务方面的表现
它都还非常不错的 就表现非常好的
然后这块还是这个任务 任务的一个情况
就这里有对应的权重 OK
然后底下就是说有这个具体细节了
就比如说在这类ALF这种任务上 它的表现
Gb4它的评分 我们可以明显看到它是86 对吧
它其实已经高于这个就是Gb4了 已经比它高了
就是说在这个日常生活的这种数据级上表现已经非常高了
然后在这个we shop 网络购物这块的话它还差点意思
但是也很高了
然后在这个mantra web这个方面的表现13.5
这个稍微差一点 这个稍微差一点 70B的稍微差一点
然后知识图谱方面的表现我们看到还可以
基本上跟这个4的话会接近的
然后在操作系统方面的表现也是稍微差点
但是还可以 比lama2要好很多
在数据库方面的表现我们看到它是非常高的 对吧
然后整体的表现2.55 这个2.75要远高于3.5
也远高于lama2
然后在这个Gb4方面的就是说可能稍微持平了
因为它的数据有些是用Gb4构建的
所以说我觉得它超不过Gb4也是可以理解
然后在这个泛化能力的这些数据级的表现
比如说像就是这个科学的这种数据上
这个miniweb的数据上web的还有这些数据级上
我们看到表现就相对的话都提升了非常多
在比lama2要提升了将近比如说一倍了 一倍多
将近两倍 已经提升了非常多了
这个虽然说不及4
但是已经比这个跟3.5基本上持平了
这个最高的70B 然后在通用任务方面的能力表现
我们看到它跟lama2基本上没有丧失太多的一个通用能力
因为我们都知道用lama2微调的话
会对它原有的通用能力会有丧失
而我们通过这几个数据级的这几个测评之后
发现它的表现还是不错的
OK 这大概就是关于这个项目的一个大概的介绍
我们看它的残差就是误差方面
这个表现也是非常不错
像lama2这个误差就太大了 残差这个表现非常大
在知识图谱和在通用的微shop和ALF Word方面的表现就比较差一些
那么agent LLM它的表现就非常好
当然比ZB4还差点意思 但是就是说已经相对相当可以了
这是它提供的一个新的方法
我们看到它的一个在具体数据上的一个表现
就lama2基本上是比如针对这个任务
这个ALF Word这个任务表现非常差
它提的一个什么任务呢
就是说日常家庭的一个家庭任务
就是家庭清扫这么一个任务
比如说instructor是把两个肥皂扔到垃圾桶里
那么的话lama2就执行失败了
然后agent LLM执行还可以 基本上执行成功了
经过多轮之后执行成功了
所以的话我们看到它的表现还是非常不错的
这样这边还有一个对比 它的一个能力的对比
比如说只是在通用的话 比如7B表现的话是综合是0.63
然后比如说在数据集内的表现非常高 1.96
我们看它的一个表现能力
这块有一个对应的 比如说不同的参数level在表现
我们看到参数越好越高 这个表现越好 对吧
OK 这大概就是它的一个情况
就是关于agent timing的一个介绍
然后这个项目我觉得还是非常有价值的
应该说对于促进我们未来在构建大模型本身的agent能力方面
是提供了一个新的思路
以前我们是要从0到1挨个去敲代码去搞
那么现在的话其实可以从训练层面又提供了新的思路
可以通过训练来提升大模型底层的任务处理能力
OK 那可能未来咱们很多场景里面是要把两者结合起来来用
因为如果说你全部用原先的那种agent
不用微调 用去原先的那种传统的agent方式的话
它会面临一个问题 就是你每个场景都会定制一个agent
那个开发量也很大 那么的话就是说对于如果说一个场景里面
它设计的agent的任务非常多的时候
大模型在这方面表现很差的时候
这个时候你就可以从模型本身入手来做微调它
采用agent timing这种方式来做微调
那么它可能会表现的对你的这种成本很多方面的控制来说是非常有价值的
好的 我们今天关于这个项目的一个介绍就到这里
希望对大家有些启发 如果您觉得不错的话
请帮忙一键三连 谢谢
