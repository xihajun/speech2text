 If you just try to imagine and look into the future, which is of course a very difficult thing to do, but let's try to do it anyway.
 Where do we think things will be in five years or in ten years?
 I mean, progress has been really stunning over the past few years. Maybe it will be a little bit slower.
 But still, if you extrapolate this kind of progress, you'll be in a very, very different place in five years, let alone ten years.
 It doesn't seem implausible. It doesn't seem at all implausible that we will have computers, data centers, that are much smarter than people.
 And by smarter, I don't mean just have more memory or have more knowledge, but I also mean have deeper insight into the same subjects that we people are studying and looking into.
 It means learn even faster than people.
 What could such AIs do? I don't know.
 Certainly, if such an AI were the basis of some artificial life, it would be, well, how do you even think about it if you have some very powerful data center that's also alive, in a sense?
 That's what you're talking about.
 And when I imagine this world, my reaction is, gosh, this is very unpredictable what's going to happen, very unpredictable.
 But there is a bare minimum which we can articulate, that if such very, very intelligent, super intelligent data centers are being built at all, we want those data centers to hold warm and positive feelings towards people, towards humanity.
 Because this is going to be non-human life, in a sense.
 Potentially, it could potentially be that.
 And so I would want that any instance of such super intelligence to have warm feelings towards humanity.
 And so this is what we are doing with the Super Alignment Project.
 We are saying, hey, if you just allow yourself, if you just accept that the progress that you've seen, maybe it will be slower, but it will continue.
 If you allow yourself that, then you can start doing productive work today to build the science so that we will be able to handle the problem of controlling such future super intelligence, of imprinting onto them a strong desire to be nice and kind to people.
 Because those data centers, right, they'll be really quite powerful.
 You know, there'll probably be many of them, the world will be very complicated.
 But somehow, to the extent that they are autonomous, to the extent that they are agents, to the extent they are beings, I want them to be pro-social, pro-human social.
 The friendship piece, I think, is optional, but I do think that we want to have very pro-social AI.
 I think it's possible. I don't think it's guaranteed, but I think it's possible.
 I think it's going to be possible and the possibility of that will increase insofar as more and more people allow themselves to look into the future, into the five to 10 year future.
 And just ask yourself, what do you expect AI to be able to do then?
 How capable do you expect it to be then?
 And I think that with each passing year, if indeed AI continues to improve and as people get to experience, because right now we are talking, making arguments.
 But if you actually get to experience, oh, gosh, the AI from last year, which was really helpful this year, puts the previous one to shame and you go, OK.
 And then one year later and one year starting to do science, the AI software engineer is starting to get really quite good.
 Let's say. I think that will create a lot more desire in people for what you just described, for the future superintelligence to be very pro-social.
 You know, I think there's going to be a lot of disagreement. It's going to be a lot of political questions.
 But I think that as people see AI actually getting better, as people experience it, the desire for the pro-social super intelligence,
 the humanity loving superintelligence, you know, as much as it can be done, will increase.
 And on the scientific problem, you know, I think right now it's still being an area we're not that many people are working on.
 Our AIs are getting powerful enough that you can really start studying it productively.
 We'll have some very exciting research to share soon.
 But I would say that's the big picture situation here.
 Just really, it really boils down to look at what you've experienced with AI up until now.
 Ask yourself, like, is it slowing down? Will it slow down next year?
 Like, we will see and we will experience it again and again.
 And I think it will keep and what needs to be done will keep becoming clearer.
 Oh, it is indeed the case that we are in an acceleration phase.
 You know, it's hard to say, you know, multiple forces will come into play.
 Some forces are accelerating forces and some forces are decelerating.
 So, for example, the cost and scale are a decelerating force.
 The fact that our data is finite is a decelerating force to some degree.
 With the data in particular, I just think it won't be, it just won't be an issue because we'll figure out something else.
 But then you might argue that the size of the engineering project is a decelerating force, just the complexity of management.
 On the other hand, the amount of investment is an accelerating force, the amount of interest from people, from engineers, scientists is an accelerating force.
 And I think there is one other accelerating force, and that is the fact that biological evolution has been able to figure it out.
 And the fact that up until now, progress in AI has had up until this point, this weird property that it's kind of been.
 You know, it's been very hard to execute on, but in some sense, it's also been more straightforward than one would have expected from sense.
 I don't know much physics, but my understanding is that if you want to make progress in quantum physics or something,
 you need to be really intelligent and spend many years in grad school studying how these things work.
 Whereas with AI, you have people come in, get up to speed quickly, start making contributions quickly, it has the flavor is somehow different.
 Somehow it's very, there is some kind of, there's a lot of give to this particular area of research.
 And I think this is also an accelerating force. How will it all play out remains to be seen.
 Like it may be that somehow the scale required, the engineering complexity will start to make it so that the rate of progress will start to slow down.
 It will still continue, but maybe not as quick as we had before.
 Or maybe the forces which are coming together to push it will be such that it will be as fast for maybe a few more years before it will start to slow down.
 If at all that's, that would be my articulation here.
